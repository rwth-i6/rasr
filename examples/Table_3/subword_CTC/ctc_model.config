#!rnn.py
import sys
sys.setrecursionlimit(4000)

batch_size = 10000
batching = 'random'
cache_size = '0'
cleanup_old_models = {'keep': [200, 210, 220, 230, 240]}
dev = { 'class': 'ExternSprintDataset',
  'partitionEpoch': 1,
  'sprintConfigStr': '--config=sprint.dev.config --*.LOGFILE=nn-trainer.dev.log --*.TASK=1 --*.corpus.segment-order-shuffle=true '
                     '--*.segment-order-sort-by-time-length=true --*.segment-order-sort-by-time-length-chunk-size=50',
  'sprintTrainerExecPath': '/u/zhou/rasr-dev/arch/linux-x86_64-standard-label_sync_decoding/nn-trainer.linux-x86_64-standard-label_sync_decoding'}
device = 'gpu'
gradient_clip = 0
gradient_noise = 0
learning_rate = 0.001
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
learning_rate_file = 'learning_rates'
log = ['./crnn.log']
log_verbosity = 3
max_seqs = 128
min_learning_rate = 1e-05
model = '/u/zhou/asr-exps/librispeech/2021-06-16_ADSM/work/crnn/custom_sprint_training/CustomCRNNSprintTrainingJob.zjJAYpTLXtoH/output/models/epoch'
multiprocessing = True
nadam = True
network = { 'conformer_10_conv_mod_bn': { 'class': 'batch_norm',
                                'delay_sample_update': True,
                                'epsilon': 1e-05,
                                'from': 'conformer_10_conv_mod_depthwise_conv',
                                'momentum': 0.1,
                                'update_sample_only_in_training': True},
  'conformer_10_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_10_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_10_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_10_conv_mod_pointwise_conv_2'},
  'conformer_10_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_10_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_10_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_10_ffmod_1_half_res_add'},
  'conformer_10_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_10_conv_mod_ln', 'n_out': 1024},
  'conformer_10_conv_mod_pointwise_conv_2': { 'L2': 0.0001,
                                              'activation': None,
                                              'class': 'linear',
                                              'from': 'conformer_10_conv_mod_swish',
                                              'n_out': 512},
  'conformer_10_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_10_conv_mod_dropout', 'conformer_10_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_10_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_10_conv_mod_bn'},
  'conformer_10_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_10_ffmod_1_dropout_linear'},
  'conformer_10_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.1,
                                           'from': 'conformer_10_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_10_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_10_ffmod_1_dropout', 'conformer_9_output']},
  'conformer_10_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_10_ffmod_1_ln', 'n_out': 2048},
  'conformer_10_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_9_output'},
  'conformer_10_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_10_ffmod_2_dropout_linear'},
  'conformer_10_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.1,
                                           'from': 'conformer_10_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_10_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_10_ffmod_2_dropout', 'conformer_10_mhsa_mod_res_add']},
  'conformer_10_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_10_ffmod_2_ln', 'n_out': 2048},
  'conformer_10_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_10_mhsa_mod_res_add'},
  'conformer_10_mhsa_mod_att_linear': { 'L2': 0.0001,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_10_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_10_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_10_mhsa_mod_att_linear'},
  'conformer_10_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_10_conv_mod_res_add'},
  'conformer_10_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_10_mhsa_mod_ln', 'n_out': 64},
  'conformer_10_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_10_mhsa_mod_dropout', 'conformer_10_conv_mod_res_add'], 'kind': 'add'},
  'conformer_10_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                            'class': 'self_attention',
                                            'from': 'conformer_10_mhsa_mod_ln',
                                            'key_shift': 'conformer_10_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_10_output': {'class': 'layer_norm', 'from': 'conformer_10_ffmod_2_half_res_add'},
  'conformer_11_conv_mod_bn': { 'class': 'batch_norm',
                                'delay_sample_update': True,
                                'epsilon': 1e-05,
                                'from': 'conformer_11_conv_mod_depthwise_conv',
                                'momentum': 0.1,
                                'update_sample_only_in_training': True},
  'conformer_11_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_11_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_11_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_11_conv_mod_pointwise_conv_2'},
  'conformer_11_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_11_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_11_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_11_ffmod_1_half_res_add'},
  'conformer_11_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_11_conv_mod_ln', 'n_out': 1024},
  'conformer_11_conv_mod_pointwise_conv_2': { 'L2': 0.0001,
                                              'activation': None,
                                              'class': 'linear',
                                              'from': 'conformer_11_conv_mod_swish',
                                              'n_out': 512},
  'conformer_11_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_11_conv_mod_dropout', 'conformer_11_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_11_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_11_conv_mod_bn'},
  'conformer_11_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_11_ffmod_1_dropout_linear'},
  'conformer_11_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.1,
                                           'from': 'conformer_11_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_11_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_11_ffmod_1_dropout', 'conformer_10_output']},
  'conformer_11_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_11_ffmod_1_ln', 'n_out': 2048},
  'conformer_11_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_10_output'},
  'conformer_11_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_11_ffmod_2_dropout_linear'},
  'conformer_11_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.1,
                                           'from': 'conformer_11_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_11_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_11_ffmod_2_dropout', 'conformer_11_mhsa_mod_res_add']},
  'conformer_11_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_11_ffmod_2_ln', 'n_out': 2048},
  'conformer_11_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_11_mhsa_mod_res_add'},
  'conformer_11_mhsa_mod_att_linear': { 'L2': 0.0001,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_11_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_11_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_11_mhsa_mod_att_linear'},
  'conformer_11_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_11_conv_mod_res_add'},
  'conformer_11_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_11_mhsa_mod_ln', 'n_out': 64},
  'conformer_11_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_11_mhsa_mod_dropout', 'conformer_11_conv_mod_res_add'], 'kind': 'add'},
  'conformer_11_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                            'class': 'self_attention',
                                            'from': 'conformer_11_mhsa_mod_ln',
                                            'key_shift': 'conformer_11_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_11_output': {'class': 'layer_norm', 'from': 'conformer_11_ffmod_2_half_res_add'},
  'conformer_12_conv_mod_bn': { 'class': 'batch_norm',
                                'delay_sample_update': True,
                                'epsilon': 1e-05,
                                'from': 'conformer_12_conv_mod_depthwise_conv',
                                'momentum': 0.1,
                                'update_sample_only_in_training': True},
  'conformer_12_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_12_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_12_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_12_conv_mod_pointwise_conv_2'},
  'conformer_12_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_12_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_12_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_12_ffmod_1_half_res_add'},
  'conformer_12_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_12_conv_mod_ln', 'n_out': 1024},
  'conformer_12_conv_mod_pointwise_conv_2': { 'L2': 0.0001,
                                              'activation': None,
                                              'class': 'linear',
                                              'from': 'conformer_12_conv_mod_swish',
                                              'n_out': 512},
  'conformer_12_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_12_conv_mod_dropout', 'conformer_12_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_12_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_12_conv_mod_bn'},
  'conformer_12_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_12_ffmod_1_dropout_linear'},
  'conformer_12_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.1,
                                           'from': 'conformer_12_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_12_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_12_ffmod_1_dropout', 'conformer_11_output']},
  'conformer_12_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_12_ffmod_1_ln', 'n_out': 2048},
  'conformer_12_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_11_output'},
  'conformer_12_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_12_ffmod_2_dropout_linear'},
  'conformer_12_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.1,
                                           'from': 'conformer_12_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_12_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_12_ffmod_2_dropout', 'conformer_12_mhsa_mod_res_add']},
  'conformer_12_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_12_ffmod_2_ln', 'n_out': 2048},
  'conformer_12_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_12_mhsa_mod_res_add'},
  'conformer_12_mhsa_mod_att_linear': { 'L2': 0.0001,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_12_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_12_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_12_mhsa_mod_att_linear'},
  'conformer_12_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_12_conv_mod_res_add'},
  'conformer_12_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_12_mhsa_mod_ln', 'n_out': 64},
  'conformer_12_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_12_mhsa_mod_dropout', 'conformer_12_conv_mod_res_add'], 'kind': 'add'},
  'conformer_12_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                            'class': 'self_attention',
                                            'from': 'conformer_12_mhsa_mod_ln',
                                            'key_shift': 'conformer_12_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_12_output': {'class': 'layer_norm', 'from': 'conformer_12_ffmod_2_half_res_add'},
  'conformer_1_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_1_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_1_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_1_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_1_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_1_conv_mod_pointwise_conv_2'},
  'conformer_1_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_1_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_1_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_1_ffmod_1_half_res_add'},
  'conformer_1_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_1_conv_mod_ln', 'n_out': 1024},
  'conformer_1_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_1_conv_mod_swish', 'n_out': 512},
  'conformer_1_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_1_conv_mod_dropout', 'conformer_1_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_1_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_1_conv_mod_bn'},
  'conformer_1_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_1_ffmod_1_dropout_linear'},
  'conformer_1_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_1_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_1_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_1_ffmod_1_dropout', 'input_dropout']},
  'conformer_1_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_1_ffmod_1_ln', 'n_out': 2048},
  'conformer_1_ffmod_1_ln': {'class': 'layer_norm', 'from': 'input_dropout'},
  'conformer_1_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_1_ffmod_2_dropout_linear'},
  'conformer_1_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_1_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_1_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_1_ffmod_2_dropout', 'conformer_1_mhsa_mod_res_add']},
  'conformer_1_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_1_ffmod_2_ln', 'n_out': 2048},
  'conformer_1_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_1_mhsa_mod_res_add'},
  'conformer_1_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_1_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_1_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_1_mhsa_mod_att_linear'},
  'conformer_1_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_1_conv_mod_res_add'},
  'conformer_1_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_1_mhsa_mod_ln', 'n_out': 64},
  'conformer_1_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_1_mhsa_mod_dropout', 'conformer_1_conv_mod_res_add'], 'kind': 'add'},
  'conformer_1_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_1_mhsa_mod_ln',
                                           'key_shift': 'conformer_1_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_1_output': {'class': 'layer_norm', 'from': 'conformer_1_ffmod_2_half_res_add'},
  'conformer_2_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_2_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_2_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_2_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_2_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_2_conv_mod_pointwise_conv_2'},
  'conformer_2_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_2_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_2_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_2_ffmod_1_half_res_add'},
  'conformer_2_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_2_conv_mod_ln', 'n_out': 1024},
  'conformer_2_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_2_conv_mod_swish', 'n_out': 512},
  'conformer_2_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_2_conv_mod_dropout', 'conformer_2_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_2_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_2_conv_mod_bn'},
  'conformer_2_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_2_ffmod_1_dropout_linear'},
  'conformer_2_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_2_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_2_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_2_ffmod_1_dropout', 'conformer_1_output']},
  'conformer_2_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_2_ffmod_1_ln', 'n_out': 2048},
  'conformer_2_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_1_output'},
  'conformer_2_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_2_ffmod_2_dropout_linear'},
  'conformer_2_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_2_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_2_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_2_ffmod_2_dropout', 'conformer_2_mhsa_mod_res_add']},
  'conformer_2_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_2_ffmod_2_ln', 'n_out': 2048},
  'conformer_2_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_2_mhsa_mod_res_add'},
  'conformer_2_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_2_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_2_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_2_mhsa_mod_att_linear'},
  'conformer_2_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_2_conv_mod_res_add'},
  'conformer_2_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_2_mhsa_mod_ln', 'n_out': 64},
  'conformer_2_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_2_mhsa_mod_dropout', 'conformer_2_conv_mod_res_add'], 'kind': 'add'},
  'conformer_2_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_2_mhsa_mod_ln',
                                           'key_shift': 'conformer_2_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_2_output': {'class': 'layer_norm', 'from': 'conformer_2_ffmod_2_half_res_add'},
  'conformer_3_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_3_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_3_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_3_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_3_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_3_conv_mod_pointwise_conv_2'},
  'conformer_3_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_3_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_3_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_3_ffmod_1_half_res_add'},
  'conformer_3_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_3_conv_mod_ln', 'n_out': 1024},
  'conformer_3_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_3_conv_mod_swish', 'n_out': 512},
  'conformer_3_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_3_conv_mod_dropout', 'conformer_3_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_3_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_3_conv_mod_bn'},
  'conformer_3_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_3_ffmod_1_dropout_linear'},
  'conformer_3_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_3_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_3_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_3_ffmod_1_dropout', 'conformer_2_output']},
  'conformer_3_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_3_ffmod_1_ln', 'n_out': 2048},
  'conformer_3_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_2_output'},
  'conformer_3_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_3_ffmod_2_dropout_linear'},
  'conformer_3_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_3_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_3_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_3_ffmod_2_dropout', 'conformer_3_mhsa_mod_res_add']},
  'conformer_3_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_3_ffmod_2_ln', 'n_out': 2048},
  'conformer_3_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_3_mhsa_mod_res_add'},
  'conformer_3_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_3_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_3_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_3_mhsa_mod_att_linear'},
  'conformer_3_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_3_conv_mod_res_add'},
  'conformer_3_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_3_mhsa_mod_ln', 'n_out': 64},
  'conformer_3_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_3_mhsa_mod_dropout', 'conformer_3_conv_mod_res_add'], 'kind': 'add'},
  'conformer_3_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_3_mhsa_mod_ln',
                                           'key_shift': 'conformer_3_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_3_output': {'class': 'layer_norm', 'from': 'conformer_3_ffmod_2_half_res_add'},
  'conformer_4_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_4_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_4_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_4_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_4_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_4_conv_mod_pointwise_conv_2'},
  'conformer_4_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_4_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_4_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_4_ffmod_1_half_res_add'},
  'conformer_4_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_4_conv_mod_ln', 'n_out': 1024},
  'conformer_4_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_4_conv_mod_swish', 'n_out': 512},
  'conformer_4_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_4_conv_mod_dropout', 'conformer_4_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_4_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_4_conv_mod_bn'},
  'conformer_4_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_4_ffmod_1_dropout_linear'},
  'conformer_4_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_4_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_4_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_4_ffmod_1_dropout', 'conformer_3_output']},
  'conformer_4_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_4_ffmod_1_ln', 'n_out': 2048},
  'conformer_4_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_3_output'},
  'conformer_4_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_4_ffmod_2_dropout_linear'},
  'conformer_4_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_4_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_4_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_4_ffmod_2_dropout', 'conformer_4_mhsa_mod_res_add']},
  'conformer_4_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_4_ffmod_2_ln', 'n_out': 2048},
  'conformer_4_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_4_mhsa_mod_res_add'},
  'conformer_4_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_4_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_4_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_4_mhsa_mod_att_linear'},
  'conformer_4_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_4_conv_mod_res_add'},
  'conformer_4_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_4_mhsa_mod_ln', 'n_out': 64},
  'conformer_4_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_4_mhsa_mod_dropout', 'conformer_4_conv_mod_res_add'], 'kind': 'add'},
  'conformer_4_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_4_mhsa_mod_ln',
                                           'key_shift': 'conformer_4_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_4_output': {'class': 'layer_norm', 'from': 'conformer_4_ffmod_2_half_res_add'},
  'conformer_5_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_5_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_5_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_5_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_5_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_5_conv_mod_pointwise_conv_2'},
  'conformer_5_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_5_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_5_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_5_ffmod_1_half_res_add'},
  'conformer_5_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_5_conv_mod_ln', 'n_out': 1024},
  'conformer_5_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_5_conv_mod_swish', 'n_out': 512},
  'conformer_5_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_5_conv_mod_dropout', 'conformer_5_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_5_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_5_conv_mod_bn'},
  'conformer_5_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_5_ffmod_1_dropout_linear'},
  'conformer_5_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_5_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_5_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_5_ffmod_1_dropout', 'conformer_4_output']},
  'conformer_5_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_5_ffmod_1_ln', 'n_out': 2048},
  'conformer_5_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_4_output'},
  'conformer_5_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_5_ffmod_2_dropout_linear'},
  'conformer_5_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_5_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_5_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_5_ffmod_2_dropout', 'conformer_5_mhsa_mod_res_add']},
  'conformer_5_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_5_ffmod_2_ln', 'n_out': 2048},
  'conformer_5_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_5_mhsa_mod_res_add'},
  'conformer_5_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_5_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_5_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_5_mhsa_mod_att_linear'},
  'conformer_5_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_5_conv_mod_res_add'},
  'conformer_5_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_5_mhsa_mod_ln', 'n_out': 64},
  'conformer_5_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_5_mhsa_mod_dropout', 'conformer_5_conv_mod_res_add'], 'kind': 'add'},
  'conformer_5_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_5_mhsa_mod_ln',
                                           'key_shift': 'conformer_5_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_5_output': {'class': 'layer_norm', 'from': 'conformer_5_ffmod_2_half_res_add'},
  'conformer_6_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_6_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_6_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_6_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_6_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_6_conv_mod_pointwise_conv_2'},
  'conformer_6_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_6_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_6_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_6_ffmod_1_half_res_add'},
  'conformer_6_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_6_conv_mod_ln', 'n_out': 1024},
  'conformer_6_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_6_conv_mod_swish', 'n_out': 512},
  'conformer_6_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_6_conv_mod_dropout', 'conformer_6_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_6_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_6_conv_mod_bn'},
  'conformer_6_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_6_ffmod_1_dropout_linear'},
  'conformer_6_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_6_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_6_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_6_ffmod_1_dropout', 'conformer_5_output']},
  'conformer_6_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_6_ffmod_1_ln', 'n_out': 2048},
  'conformer_6_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_5_output'},
  'conformer_6_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_6_ffmod_2_dropout_linear'},
  'conformer_6_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_6_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_6_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_6_ffmod_2_dropout', 'conformer_6_mhsa_mod_res_add']},
  'conformer_6_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_6_ffmod_2_ln', 'n_out': 2048},
  'conformer_6_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_6_mhsa_mod_res_add'},
  'conformer_6_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_6_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_6_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_6_mhsa_mod_att_linear'},
  'conformer_6_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_6_conv_mod_res_add'},
  'conformer_6_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_6_mhsa_mod_ln', 'n_out': 64},
  'conformer_6_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_6_mhsa_mod_dropout', 'conformer_6_conv_mod_res_add'], 'kind': 'add'},
  'conformer_6_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_6_mhsa_mod_ln',
                                           'key_shift': 'conformer_6_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_6_output': {'class': 'layer_norm', 'from': 'conformer_6_ffmod_2_half_res_add'},
  'conformer_7_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_7_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_7_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_7_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_7_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_7_conv_mod_pointwise_conv_2'},
  'conformer_7_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_7_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_7_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_7_ffmod_1_half_res_add'},
  'conformer_7_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_7_conv_mod_ln', 'n_out': 1024},
  'conformer_7_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_7_conv_mod_swish', 'n_out': 512},
  'conformer_7_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_7_conv_mod_dropout', 'conformer_7_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_7_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_7_conv_mod_bn'},
  'conformer_7_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_7_ffmod_1_dropout_linear'},
  'conformer_7_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_7_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_7_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_7_ffmod_1_dropout', 'conformer_6_output']},
  'conformer_7_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_7_ffmod_1_ln', 'n_out': 2048},
  'conformer_7_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_6_output'},
  'conformer_7_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_7_ffmod_2_dropout_linear'},
  'conformer_7_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_7_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_7_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_7_ffmod_2_dropout', 'conformer_7_mhsa_mod_res_add']},
  'conformer_7_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_7_ffmod_2_ln', 'n_out': 2048},
  'conformer_7_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_7_mhsa_mod_res_add'},
  'conformer_7_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_7_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_7_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_7_mhsa_mod_att_linear'},
  'conformer_7_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_7_conv_mod_res_add'},
  'conformer_7_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_7_mhsa_mod_ln', 'n_out': 64},
  'conformer_7_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_7_mhsa_mod_dropout', 'conformer_7_conv_mod_res_add'], 'kind': 'add'},
  'conformer_7_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_7_mhsa_mod_ln',
                                           'key_shift': 'conformer_7_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_7_output': {'class': 'layer_norm', 'from': 'conformer_7_ffmod_2_half_res_add'},
  'conformer_8_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_8_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_8_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_8_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_8_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_8_conv_mod_pointwise_conv_2'},
  'conformer_8_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_8_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_8_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_8_ffmod_1_half_res_add'},
  'conformer_8_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_8_conv_mod_ln', 'n_out': 1024},
  'conformer_8_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_8_conv_mod_swish', 'n_out': 512},
  'conformer_8_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_8_conv_mod_dropout', 'conformer_8_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_8_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_8_conv_mod_bn'},
  'conformer_8_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_8_ffmod_1_dropout_linear'},
  'conformer_8_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_8_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_8_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_8_ffmod_1_dropout', 'conformer_7_output']},
  'conformer_8_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_8_ffmod_1_ln', 'n_out': 2048},
  'conformer_8_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_7_output'},
  'conformer_8_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_8_ffmod_2_dropout_linear'},
  'conformer_8_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_8_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_8_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_8_ffmod_2_dropout', 'conformer_8_mhsa_mod_res_add']},
  'conformer_8_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_8_ffmod_2_ln', 'n_out': 2048},
  'conformer_8_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_8_mhsa_mod_res_add'},
  'conformer_8_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_8_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_8_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_8_mhsa_mod_att_linear'},
  'conformer_8_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_8_conv_mod_res_add'},
  'conformer_8_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_8_mhsa_mod_ln', 'n_out': 64},
  'conformer_8_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_8_mhsa_mod_dropout', 'conformer_8_conv_mod_res_add'], 'kind': 'add'},
  'conformer_8_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_8_mhsa_mod_ln',
                                           'key_shift': 'conformer_8_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_8_output': {'class': 'layer_norm', 'from': 'conformer_8_ffmod_2_half_res_add'},
  'conformer_9_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_9_conv_mod_depthwise_conv',
                               'momentum': 0.1,
                               'update_sample_only_in_training': True},
  'conformer_9_conv_mod_depthwise_conv': { 'L2': 0.0001,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_9_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_9_conv_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_9_conv_mod_pointwise_conv_2'},
  'conformer_9_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_9_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_9_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_9_ffmod_1_half_res_add'},
  'conformer_9_conv_mod_pointwise_conv_1': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_9_conv_mod_ln', 'n_out': 1024},
  'conformer_9_conv_mod_pointwise_conv_2': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conformer_9_conv_mod_swish', 'n_out': 512},
  'conformer_9_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_9_conv_mod_dropout', 'conformer_9_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_9_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_9_conv_mod_bn'},
  'conformer_9_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_9_ffmod_1_dropout_linear'},
  'conformer_9_ffmod_1_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_9_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_9_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_9_ffmod_1_dropout', 'conformer_8_output']},
  'conformer_9_ffmod_1_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_9_ffmod_1_ln', 'n_out': 2048},
  'conformer_9_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_8_output'},
  'conformer_9_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_9_ffmod_2_dropout_linear'},
  'conformer_9_ffmod_2_dropout_linear': { 'L2': 0.0001,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.1,
                                          'from': 'conformer_9_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_9_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_9_ffmod_2_dropout', 'conformer_9_mhsa_mod_res_add']},
  'conformer_9_ffmod_2_linear_swish': {'L2': 0.0001, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_9_ffmod_2_ln', 'n_out': 2048},
  'conformer_9_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_9_mhsa_mod_res_add'},
  'conformer_9_mhsa_mod_att_linear': { 'L2': 0.0001,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_9_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_9_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'conformer_9_mhsa_mod_att_linear'},
  'conformer_9_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_9_conv_mod_res_add'},
  'conformer_9_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_9_mhsa_mod_ln', 'n_out': 64},
  'conformer_9_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_9_mhsa_mod_dropout', 'conformer_9_conv_mod_res_add'], 'kind': 'add'},
  'conformer_9_mhsa_mod_self_attention': { 'attention_dropout': 0.1,
                                           'class': 'self_attention',
                                           'from': 'conformer_9_mhsa_mod_ln',
                                           'key_shift': 'conformer_9_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_9_output': {'class': 'layer_norm', 'from': 'conformer_9_ffmod_2_half_res_add'},
  'conv_1': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_source',
              'n_out': 32,
              'padding': 'same',
              'with_bias': True},
  'conv_1_pool': {'class': 'pool', 'from': 'conv_1', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv_2': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_1_pool',
              'n_out': 64,
              'padding': 'same',
              'strides': (2, 1),
              'with_bias': True},
  'conv_3': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_2',
              'n_out': 64,
              'padding': 'same',
              'strides': (2, 1),
              'with_bias': True},
  'conv_merged': {'axes': 'static', 'class': 'merge_dims', 'from': 'conv_3'},
  'conv_source': {'axis': 'F', 'class': 'split_dims', 'dims': (-1, 1), 'from': 'source'},
  'input_dropout': {'class': 'copy', 'dropout': 0.1, 'from': 'input_linear'},
  'input_linear': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'conv_merged', 'n_out': 512, 'with_bias': False},
  'output': { 'class': 'softmax',
              'from': 'conformer_12_output',
              'loss': 'fast_bw',
              'loss_opts': { 'sprint_opts': { 'minPythonControlVersion': 4,
                                              'numInstances': 2,
                                              'sprintConfigStr': '--config=sprint.loss.config --*.LOGFILE=nn-trainer.loss.log --*.TASK=1',
                                              'sprintExecPath': '/u/zhou/rasr-dev/arch/linux-x86_64-standard-label_sync_decoding/nn-trainer.linux-x86_64-standard-label_sync_decoding',
                                              'usePythonSegmentOrder': False},
                             'tdp_scale': 0.0},
              'n_out': 5046,
              'target': None},
  'source': {'class': 'eval', 'eval': "self.network.get_config().typed_value('transform')(source(0, as_data=True), network=self.network)"}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 20
newbob_multi_update_interval = 1
num_epochs = 240
num_inputs = 50
num_outputs = 5046
optimizer_epsilon = 1e-08
preload_from_files = { 'base': { 'filename': '/u/zhou/asr-exps/librispeech/2021-06-16_ADSM/work/crnn/custom_sprint_training/CustomCRNNSprintTrainingJob.CZA48XV1DUog/output/models/epoch.240',
            'ignore_missing': True,
            'init_for_train': True}}
save_interval = 1
sis_dependency = '/u/zhou/asr-exps/librispeech/2021-06-16_ADSM/work/crnn/custom_sprint_training/CustomCRNNSprintTrainingJob.CZA48XV1DUog/output/models/epoch.240.meta'
start_batch = 'auto'
start_epoch = 'auto'
target = 'classes'
task = 'train'
train = { 'class': 'ExternSprintDataset',
  'partitionEpoch': 20,
  'sprintConfigStr': '--config=sprint.train.config --*.LOGFILE=nn-trainer.train.log --*.TASK=1 --*.corpus.segment-order-shuffle=true '
                     '--*.segment-order-sort-by-time-length=true --*.segment-order-sort-by-time-length-chunk-size=1000',
  'sprintTrainerExecPath': '/u/zhou/rasr-dev/arch/linux-x86_64-standard-label_sync_decoding/nn-trainer.linux-x86_64-standard-label_sync_decoding'}
truncation = -1
update_on_device = True
use_tensorflow = True
window = 1
config = {}

locals().update(**config)

# for debug only
def summary(name, x):
  """
  :param str name:
  :param tf.Tensor x: (batch,time,feature)
  """
  import tensorflow as tf
  # tf.summary.image wants [batch_size, height,  width, channels],
  # we have (batch, time, feature).
  img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
  img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
  tf.summary.image(name, img, max_outputs=10)
  tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
  mean = tf.reduce_mean(x)
  tf.summary.scalar("%s_mean" % name, mean)
  stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
  tf.summary.scalar("%s_stddev" % name, stddev)
  tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))


def _mask(x, batch_axis, axis, pos, max_amount):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int batch_axis:
  :param int axis:
  :param tf.Tensor pos: (batch,)
  :param int|tf.Tensor max_amount: inclusive
  """
  import tensorflow as tf
  ndim = x.get_shape().ndims
  n_batch = tf.shape(x)[batch_axis]
  dim = tf.shape(x)[axis]
  amount = tf.random_uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
  pos2 = tf.minimum(pos + amount, dim)
  idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
  pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
  pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
  cond = tf.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
  if batch_axis > axis:
    cond = tf.transpose(cond)  # (dim,batch)
  cond = tf.reshape(cond, [tf.shape(x)[i] if i in (batch_axis, axis) else 1 for i in range(ndim)])
  from TFUtil import where_bc
  x = where_bc(cond, 0.0, x)
  return x


def random_mask(x, batch_axis, axis, min_num, max_num, max_dims):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int batch_axis:
  :param int axis:
  :param int|tf.Tensor min_num:
  :param int|tf.Tensor max_num: inclusive
  :param int|tf.Tensor max_dims: inclusive
  """
  import tensorflow as tf
  n_batch = tf.shape(x)[batch_axis]
  if isinstance(min_num, int) and isinstance(max_num, int) and min_num == max_num:
    num = min_num
  else:
    num = tf.random_uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
  # https://github.com/tensorflow/tensorflow/issues/9260
  # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
  z = -tf.log(-tf.log(tf.random_uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
  _, indices = tf.nn.top_k(z, num if isinstance(num, int) else tf.reduce_max(num))
  # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
  # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
  if isinstance(num, int):
    for i in range(num):
      x = _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims)
  else:
    _, x = tf.while_loop( cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
                          body=lambda i, x: ( i + 1,
                                              tf.where( tf.less(i, num),
                                                        _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims),
                                                        x ) 
                                            ),
                          loop_vars=(0, x)
                        )
  return x


def transform(data, network):
  # to be adjusted (20-50%)
  max_time_num = 1
  max_time = 15

  max_feature_num = 5
  max_feature = 5

  # halved before this step
  conservatvie_step = 2000

  x = data.placeholder
  import tensorflow as tf
  # summary("features", x)
  step = network.global_train_step
  increase_flag = tf.where(tf.greater_equal(step, conservatvie_step), 0, 1)

  def get_masked():
    x_masked = x
    x_masked = random_mask( x_masked, batch_axis=data.batch_dim_axis, axis=data.time_dim_axis,
                            min_num=0, max_num=tf.maximum(tf.shape(x)[data.time_dim_axis]//int(1/0.70*max_time), max_time_num) // (1+increase_flag),
                            max_dims=max_time
                          )
    x_masked = random_mask( x_masked, batch_axis=data.batch_dim_axis, axis=data.feature_dim_axis,
                            min_num=0, max_num=max_feature_num // (1+increase_flag),
                            max_dims=max_feature
                          )
    #summary("features_mask", x_masked)
    return x_masked
  x = network.cond_on_train(get_masked, lambda: x)
  return x

# (const) + linear decay w.r.t. iterations(steps)
def dynamic_learning_rate(*, network, global_train_step, learning_rate, **kwargs):
  # -- need to be adjusted w.r.t. training -- #
  peakLR     = 8e-5
  decayLR    = 1e-5
  finalLR    = 1e-6
  constEpoch = 60
  decayEpoch = 140
  totalEpoch = 240
  nStep      = 2110 # steps/epoch depending on batch_size

  # -- derived -- #
  assert constEpoch + decayEpoch <= totalEpoch
  steps1 = constEpoch * nStep
  if steps1 == 0:
    steps1 == 1
  steps2 = decayEpoch * nStep
  stepSize2 = (peakLR - decayLR) / steps2
  steps2 = steps1 + steps2
  steps3 = (totalEpoch - constEpoch - decayEpoch) * nStep
  if steps3 == 0:
    stepSize3 = 0
  else:
    stepSize3 = (decayLR - finalLR) / steps3

  import tensorflow as tf
  n = tf.cast(global_train_step, tf.float32)
  return tf.where(global_train_step <= steps1, peakLR,
             tf.where(global_train_step <= steps2, peakLR - stepSize2 * (n - steps1),
                 tf.maximum(decayLR - stepSize3 * (n - steps2), finalLR)))


