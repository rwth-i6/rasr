#!rnn.py
import sys
sys.setrecursionlimit(4000)

batch_size = 10000
batching = 'random'
cache_size = '0'
chunking = '64:32'
cleanup_old_models = False
gradient_clip = 0
gradient_noise = 0.1
learning_rate = 0.0009
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
max_seqs = 128
multiprocessing = True
nadam = True
network = { 'conformer_10_conv_mod_bn': { 'class': 'batch_norm',
                                'epsilon': 1e-05,
                                'from': 'conformer_10_conv_mod_depthwise_conv',
                                'momentum': 0.0,
                                'update_sample_only_in_training': True,
                                'use_sample': 1.0},
  'conformer_10_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_10_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_10_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_10_conv_mod_pointwise_conv_2'},
  'conformer_10_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_10_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_10_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_10_ffmod_1_half_res_add'},
  'conformer_10_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_10_conv_mod_ln', 'n_out': 1024},
  'conformer_10_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_10_conv_mod_swish', 'n_out': 512},
  'conformer_10_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_10_conv_mod_dropout', 'conformer_10_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_10_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_10_conv_mod_bn'},
  'conformer_10_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_10_ffmod_1_dropout_linear'},
  'conformer_10_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0,
                                           'from': 'conformer_10_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_10_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_10_ffmod_1_dropout', 'conformer_9_output']},
  'conformer_10_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_10_ffmod_1_ln', 'n_out': 2048},
  'conformer_10_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_9_output'},
  'conformer_10_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_10_ffmod_2_dropout_linear'},
  'conformer_10_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0,
                                           'from': 'conformer_10_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_10_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_10_ffmod_2_dropout', 'conformer_10_mhsa_mod_res_add']},
  'conformer_10_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_10_ffmod_2_ln', 'n_out': 2048},
  'conformer_10_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_10_mhsa_mod_res_add'},
  'conformer_10_mhsa_mod_att_linear': { 'L2': 5e-06,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_10_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_10_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_10_mhsa_mod_att_linear'},
  'conformer_10_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_10_conv_mod_res_add'},
  'conformer_10_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_10_mhsa_mod_ln', 'n_out': 64},
  'conformer_10_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_10_mhsa_mod_dropout', 'conformer_10_conv_mod_res_add'], 'kind': 'add'},
  'conformer_10_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                            'class': 'self_attention',
                                            'from': 'conformer_10_mhsa_mod_ln',
                                            'key_shift': 'conformer_10_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_10_output': {'class': 'layer_norm', 'from': 'conformer_10_ffmod_2_half_res_add'},
  'conformer_11_conv_mod_bn': { 'class': 'batch_norm',
                                'epsilon': 1e-05,
                                'from': 'conformer_11_conv_mod_depthwise_conv',
                                'momentum': 0.0,
                                'update_sample_only_in_training': True,
                                'use_sample': 1.0},
  'conformer_11_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_11_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_11_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_11_conv_mod_pointwise_conv_2'},
  'conformer_11_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_11_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_11_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_11_ffmod_1_half_res_add'},
  'conformer_11_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_11_conv_mod_ln', 'n_out': 1024},
  'conformer_11_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_11_conv_mod_swish', 'n_out': 512},
  'conformer_11_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_11_conv_mod_dropout', 'conformer_11_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_11_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_11_conv_mod_bn'},
  'conformer_11_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_11_ffmod_1_dropout_linear'},
  'conformer_11_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0,
                                           'from': 'conformer_11_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_11_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_11_ffmod_1_dropout', 'conformer_10_output']},
  'conformer_11_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_11_ffmod_1_ln', 'n_out': 2048},
  'conformer_11_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_10_output'},
  'conformer_11_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_11_ffmod_2_dropout_linear'},
  'conformer_11_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0,
                                           'from': 'conformer_11_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_11_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_11_ffmod_2_dropout', 'conformer_11_mhsa_mod_res_add']},
  'conformer_11_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_11_ffmod_2_ln', 'n_out': 2048},
  'conformer_11_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_11_mhsa_mod_res_add'},
  'conformer_11_mhsa_mod_att_linear': { 'L2': 5e-06,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_11_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_11_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_11_mhsa_mod_att_linear'},
  'conformer_11_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_11_conv_mod_res_add'},
  'conformer_11_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_11_mhsa_mod_ln', 'n_out': 64},
  'conformer_11_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_11_mhsa_mod_dropout', 'conformer_11_conv_mod_res_add'], 'kind': 'add'},
  'conformer_11_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                            'class': 'self_attention',
                                            'from': 'conformer_11_mhsa_mod_ln',
                                            'key_shift': 'conformer_11_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_11_output': {'class': 'layer_norm', 'from': 'conformer_11_ffmod_2_half_res_add'},
  'conformer_12_conv_mod_bn': { 'class': 'batch_norm',
                                'epsilon': 1e-05,
                                'from': 'conformer_12_conv_mod_depthwise_conv',
                                'momentum': 0.0,
                                'update_sample_only_in_training': True,
                                'use_sample': 1.0},
  'conformer_12_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_12_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_12_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_12_conv_mod_pointwise_conv_2'},
  'conformer_12_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_12_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_12_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_12_ffmod_1_half_res_add'},
  'conformer_12_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_12_conv_mod_ln', 'n_out': 1024},
  'conformer_12_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_12_conv_mod_swish', 'n_out': 512},
  'conformer_12_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_12_conv_mod_dropout', 'conformer_12_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_12_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_12_conv_mod_bn'},
  'conformer_12_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_12_ffmod_1_dropout_linear'},
  'conformer_12_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0,
                                           'from': 'conformer_12_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_12_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_12_ffmod_1_dropout', 'conformer_11_output']},
  'conformer_12_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_12_ffmod_1_ln', 'n_out': 2048},
  'conformer_12_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_11_output'},
  'conformer_12_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_12_ffmod_2_dropout_linear'},
  'conformer_12_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0,
                                           'from': 'conformer_12_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_12_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_12_ffmod_2_dropout', 'conformer_12_mhsa_mod_res_add']},
  'conformer_12_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_12_ffmod_2_ln', 'n_out': 2048},
  'conformer_12_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_12_mhsa_mod_res_add'},
  'conformer_12_mhsa_mod_att_linear': { 'L2': 5e-06,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_12_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_12_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_12_mhsa_mod_att_linear'},
  'conformer_12_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_12_conv_mod_res_add'},
  'conformer_12_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_12_mhsa_mod_ln', 'n_out': 64},
  'conformer_12_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_12_mhsa_mod_dropout', 'conformer_12_conv_mod_res_add'], 'kind': 'add'},
  'conformer_12_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                            'class': 'self_attention',
                                            'from': 'conformer_12_mhsa_mod_ln',
                                            'key_shift': 'conformer_12_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_12_output': {'class': 'layer_norm', 'from': 'conformer_12_ffmod_2_half_res_add'},
  'conformer_1_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_1_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_1_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_1_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_1_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_1_conv_mod_pointwise_conv_2'},
  'conformer_1_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_1_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_1_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_1_ffmod_1_half_res_add'},
  'conformer_1_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_1_conv_mod_ln', 'n_out': 1024},
  'conformer_1_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_1_conv_mod_swish', 'n_out': 512},
  'conformer_1_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_1_conv_mod_dropout', 'conformer_1_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_1_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_1_conv_mod_bn'},
  'conformer_1_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_1_ffmod_1_dropout_linear'},
  'conformer_1_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_1_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_1_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_1_ffmod_1_dropout', 'input_dropout']},
  'conformer_1_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_1_ffmod_1_ln', 'n_out': 2048},
  'conformer_1_ffmod_1_ln': {'class': 'layer_norm', 'from': 'input_dropout'},
  'conformer_1_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_1_ffmod_2_dropout_linear'},
  'conformer_1_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_1_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_1_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_1_ffmod_2_dropout', 'conformer_1_mhsa_mod_res_add']},
  'conformer_1_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_1_ffmod_2_ln', 'n_out': 2048},
  'conformer_1_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_1_mhsa_mod_res_add'},
  'conformer_1_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_1_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_1_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_1_mhsa_mod_att_linear'},
  'conformer_1_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_1_conv_mod_res_add'},
  'conformer_1_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_1_mhsa_mod_ln', 'n_out': 64},
  'conformer_1_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_1_mhsa_mod_dropout', 'conformer_1_conv_mod_res_add'], 'kind': 'add'},
  'conformer_1_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'mhsa_ivec_input',
                                           'key_shift': 'conformer_1_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_1_output': {'class': 'layer_norm', 'from': 'conformer_1_ffmod_2_half_res_add'},
  'conformer_2_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_2_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_2_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_2_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_2_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_2_conv_mod_pointwise_conv_2'},
  'conformer_2_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_2_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_2_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_2_ffmod_1_half_res_add'},
  'conformer_2_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_2_conv_mod_ln', 'n_out': 1024},
  'conformer_2_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_2_conv_mod_swish', 'n_out': 512},
  'conformer_2_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_2_conv_mod_dropout', 'conformer_2_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_2_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_2_conv_mod_bn'},
  'conformer_2_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_2_ffmod_1_dropout_linear'},
  'conformer_2_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_2_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_2_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_2_ffmod_1_dropout', 'conformer_1_output']},
  'conformer_2_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_2_ffmod_1_ln', 'n_out': 2048},
  'conformer_2_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_1_output'},
  'conformer_2_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_2_ffmod_2_dropout_linear'},
  'conformer_2_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_2_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_2_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_2_ffmod_2_dropout', 'conformer_2_mhsa_mod_res_add']},
  'conformer_2_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_2_ffmod_2_ln', 'n_out': 2048},
  'conformer_2_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_2_mhsa_mod_res_add'},
  'conformer_2_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_2_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_2_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_2_mhsa_mod_att_linear'},
  'conformer_2_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_2_conv_mod_res_add'},
  'conformer_2_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_2_mhsa_mod_ln', 'n_out': 64},
  'conformer_2_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_2_mhsa_mod_dropout', 'conformer_2_conv_mod_res_add'], 'kind': 'add'},
  'conformer_2_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'conformer_2_mhsa_mod_ln',
                                           'key_shift': 'conformer_2_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_2_output': {'class': 'layer_norm', 'from': 'conformer_2_ffmod_2_half_res_add'},
  'conformer_3_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_3_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_3_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_3_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_3_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_3_conv_mod_pointwise_conv_2'},
  'conformer_3_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_3_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_3_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_3_ffmod_1_half_res_add'},
  'conformer_3_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_3_conv_mod_ln', 'n_out': 1024},
  'conformer_3_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_3_conv_mod_swish', 'n_out': 512},
  'conformer_3_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_3_conv_mod_dropout', 'conformer_3_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_3_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_3_conv_mod_bn'},
  'conformer_3_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_3_ffmod_1_dropout_linear'},
  'conformer_3_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_3_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_3_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_3_ffmod_1_dropout', 'conformer_2_output']},
  'conformer_3_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_3_ffmod_1_ln', 'n_out': 2048},
  'conformer_3_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_2_output'},
  'conformer_3_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_3_ffmod_2_dropout_linear'},
  'conformer_3_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_3_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_3_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_3_ffmod_2_dropout', 'conformer_3_mhsa_mod_res_add']},
  'conformer_3_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_3_ffmod_2_ln', 'n_out': 2048},
  'conformer_3_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_3_mhsa_mod_res_add'},
  'conformer_3_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_3_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_3_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_3_mhsa_mod_att_linear'},
  'conformer_3_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_3_conv_mod_res_add'},
  'conformer_3_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_3_mhsa_mod_ln', 'n_out': 64},
  'conformer_3_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_3_mhsa_mod_dropout', 'conformer_3_conv_mod_res_add'], 'kind': 'add'},
  'conformer_3_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'conformer_3_mhsa_mod_ln',
                                           'key_shift': 'conformer_3_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_3_output': {'class': 'layer_norm', 'from': 'conformer_3_ffmod_2_half_res_add'},
  'conformer_4_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_4_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_4_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_4_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_4_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_4_conv_mod_pointwise_conv_2'},
  'conformer_4_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_4_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_4_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_4_ffmod_1_half_res_add'},
  'conformer_4_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_4_conv_mod_ln', 'n_out': 1024},
  'conformer_4_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_4_conv_mod_swish', 'n_out': 512},
  'conformer_4_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_4_conv_mod_dropout', 'conformer_4_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_4_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_4_conv_mod_bn'},
  'conformer_4_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_4_ffmod_1_dropout_linear'},
  'conformer_4_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_4_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_4_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_4_ffmod_1_dropout', 'conformer_3_output']},
  'conformer_4_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_4_ffmod_1_ln', 'n_out': 2048},
  'conformer_4_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_3_output'},
  'conformer_4_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_4_ffmod_2_dropout_linear'},
  'conformer_4_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_4_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_4_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_4_ffmod_2_dropout', 'conformer_4_mhsa_mod_res_add']},
  'conformer_4_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_4_ffmod_2_ln', 'n_out': 2048},
  'conformer_4_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_4_mhsa_mod_res_add'},
  'conformer_4_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_4_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_4_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_4_mhsa_mod_att_linear'},
  'conformer_4_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_4_conv_mod_res_add'},
  'conformer_4_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_4_mhsa_mod_ln', 'n_out': 64},
  'conformer_4_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_4_mhsa_mod_dropout', 'conformer_4_conv_mod_res_add'], 'kind': 'add'},
  'conformer_4_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'conformer_4_mhsa_mod_ln',
                                           'key_shift': 'conformer_4_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_4_output': {'class': 'layer_norm', 'from': 'conformer_4_ffmod_2_half_res_add'},
  'conformer_5_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_5_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_5_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_5_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_5_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_5_conv_mod_pointwise_conv_2'},
  'conformer_5_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_5_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_5_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_5_ffmod_1_half_res_add'},
  'conformer_5_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_5_conv_mod_ln', 'n_out': 1024},
  'conformer_5_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_5_conv_mod_swish', 'n_out': 512},
  'conformer_5_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_5_conv_mod_dropout', 'conformer_5_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_5_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_5_conv_mod_bn'},
  'conformer_5_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_5_ffmod_1_dropout_linear'},
  'conformer_5_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_5_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_5_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_5_ffmod_1_dropout', 'conformer_4_output']},
  'conformer_5_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_5_ffmod_1_ln', 'n_out': 2048},
  'conformer_5_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_4_output'},
  'conformer_5_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_5_ffmod_2_dropout_linear'},
  'conformer_5_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_5_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_5_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_5_ffmod_2_dropout', 'conformer_5_mhsa_mod_res_add']},
  'conformer_5_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_5_ffmod_2_ln', 'n_out': 2048},
  'conformer_5_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_5_mhsa_mod_res_add'},
  'conformer_5_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_5_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_5_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_5_mhsa_mod_att_linear'},
  'conformer_5_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_5_conv_mod_res_add'},
  'conformer_5_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_5_mhsa_mod_ln', 'n_out': 64},
  'conformer_5_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_5_mhsa_mod_dropout', 'conformer_5_conv_mod_res_add'], 'kind': 'add'},
  'conformer_5_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'conformer_5_mhsa_mod_ln',
                                           'key_shift': 'conformer_5_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_5_output': {'class': 'layer_norm', 'from': 'conformer_5_ffmod_2_half_res_add'},
  'conformer_6_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_6_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_6_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_6_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_6_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_6_conv_mod_pointwise_conv_2'},
  'conformer_6_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_6_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_6_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_6_ffmod_1_half_res_add'},
  'conformer_6_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_6_conv_mod_ln', 'n_out': 1024},
  'conformer_6_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_6_conv_mod_swish', 'n_out': 512},
  'conformer_6_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_6_conv_mod_dropout', 'conformer_6_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_6_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_6_conv_mod_bn'},
  'conformer_6_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_6_ffmod_1_dropout_linear'},
  'conformer_6_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_6_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_6_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_6_ffmod_1_dropout', 'conformer_5_output']},
  'conformer_6_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_6_ffmod_1_ln', 'n_out': 2048},
  'conformer_6_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_5_output'},
  'conformer_6_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_6_ffmod_2_dropout_linear'},
  'conformer_6_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_6_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_6_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_6_ffmod_2_dropout', 'conformer_6_mhsa_mod_res_add']},
  'conformer_6_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_6_ffmod_2_ln', 'n_out': 2048},
  'conformer_6_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_6_mhsa_mod_res_add'},
  'conformer_6_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_6_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_6_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_6_mhsa_mod_att_linear'},
  'conformer_6_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_6_conv_mod_res_add'},
  'conformer_6_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_6_mhsa_mod_ln', 'n_out': 64},
  'conformer_6_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_6_mhsa_mod_dropout', 'conformer_6_conv_mod_res_add'], 'kind': 'add'},
  'conformer_6_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'conformer_6_mhsa_mod_ln',
                                           'key_shift': 'conformer_6_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_6_output': {'class': 'layer_norm', 'from': 'conformer_6_ffmod_2_half_res_add'},
  'conformer_7_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_7_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_7_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_7_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_7_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_7_conv_mod_pointwise_conv_2'},
  'conformer_7_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_7_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_7_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_7_ffmod_1_half_res_add'},
  'conformer_7_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_7_conv_mod_ln', 'n_out': 1024},
  'conformer_7_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_7_conv_mod_swish', 'n_out': 512},
  'conformer_7_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_7_conv_mod_dropout', 'conformer_7_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_7_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_7_conv_mod_bn'},
  'conformer_7_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_7_ffmod_1_dropout_linear'},
  'conformer_7_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_7_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_7_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_7_ffmod_1_dropout', 'conformer_6_output']},
  'conformer_7_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_7_ffmod_1_ln', 'n_out': 2048},
  'conformer_7_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_6_output'},
  'conformer_7_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_7_ffmod_2_dropout_linear'},
  'conformer_7_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_7_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_7_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_7_ffmod_2_dropout', 'conformer_7_mhsa_mod_res_add']},
  'conformer_7_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_7_ffmod_2_ln', 'n_out': 2048},
  'conformer_7_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_7_mhsa_mod_res_add'},
  'conformer_7_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_7_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_7_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_7_mhsa_mod_att_linear'},
  'conformer_7_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_7_conv_mod_res_add'},
  'conformer_7_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_7_mhsa_mod_ln', 'n_out': 64},
  'conformer_7_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_7_mhsa_mod_dropout', 'conformer_7_conv_mod_res_add'], 'kind': 'add'},
  'conformer_7_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'conformer_7_mhsa_mod_ln',
                                           'key_shift': 'conformer_7_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_7_output': {'class': 'layer_norm', 'from': 'conformer_7_ffmod_2_half_res_add'},
  'conformer_8_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_8_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_8_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_8_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_8_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_8_conv_mod_pointwise_conv_2'},
  'conformer_8_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_8_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_8_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_8_ffmod_1_half_res_add'},
  'conformer_8_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_8_conv_mod_ln', 'n_out': 1024},
  'conformer_8_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_8_conv_mod_swish', 'n_out': 512},
  'conformer_8_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_8_conv_mod_dropout', 'conformer_8_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_8_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_8_conv_mod_bn'},
  'conformer_8_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_8_ffmod_1_dropout_linear'},
  'conformer_8_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_8_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_8_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_8_ffmod_1_dropout', 'conformer_7_output']},
  'conformer_8_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_8_ffmod_1_ln', 'n_out': 2048},
  'conformer_8_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_7_output'},
  'conformer_8_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_8_ffmod_2_dropout_linear'},
  'conformer_8_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_8_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_8_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_8_ffmod_2_dropout', 'conformer_8_mhsa_mod_res_add']},
  'conformer_8_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_8_ffmod_2_ln', 'n_out': 2048},
  'conformer_8_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_8_mhsa_mod_res_add'},
  'conformer_8_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_8_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_8_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_8_mhsa_mod_att_linear'},
  'conformer_8_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_8_conv_mod_res_add'},
  'conformer_8_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_8_mhsa_mod_ln', 'n_out': 64},
  'conformer_8_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_8_mhsa_mod_dropout', 'conformer_8_conv_mod_res_add'], 'kind': 'add'},
  'conformer_8_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'conformer_8_mhsa_mod_ln',
                                           'key_shift': 'conformer_8_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_8_output': {'class': 'layer_norm', 'from': 'conformer_8_ffmod_2_half_res_add'},
  'conformer_9_conv_mod_bn': { 'class': 'batch_norm',
                               'epsilon': 1e-05,
                               'from': 'conformer_9_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_9_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_9_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_9_conv_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_9_conv_mod_pointwise_conv_2'},
  'conformer_9_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_9_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_9_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_9_ffmod_1_half_res_add'},
  'conformer_9_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_9_conv_mod_ln', 'n_out': 1024},
  'conformer_9_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_9_conv_mod_swish', 'n_out': 512},
  'conformer_9_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_9_conv_mod_dropout', 'conformer_9_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_9_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_9_conv_mod_bn'},
  'conformer_9_ffmod_1_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_9_ffmod_1_dropout_linear'},
  'conformer_9_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_9_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_9_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_9_ffmod_1_dropout', 'conformer_8_output']},
  'conformer_9_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_9_ffmod_1_ln', 'n_out': 2048},
  'conformer_9_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_8_output'},
  'conformer_9_ffmod_2_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_9_ffmod_2_dropout_linear'},
  'conformer_9_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0,
                                          'from': 'conformer_9_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_9_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_9_ffmod_2_dropout', 'conformer_9_mhsa_mod_res_add']},
  'conformer_9_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_9_ffmod_2_ln', 'n_out': 2048},
  'conformer_9_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_9_mhsa_mod_res_add'},
  'conformer_9_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_9_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_9_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0, 'from': 'conformer_9_mhsa_mod_att_linear'},
  'conformer_9_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_9_conv_mod_res_add'},
  'conformer_9_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_9_mhsa_mod_ln', 'n_out': 64},
  'conformer_9_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_9_mhsa_mod_dropout', 'conformer_9_conv_mod_res_add'], 'kind': 'add'},
  'conformer_9_mhsa_mod_self_attention': { 'attention_dropout': 0,
                                           'class': 'self_attention',
                                           'from': 'conformer_9_mhsa_mod_ln',
                                           'key_shift': 'conformer_9_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_9_output': {'class': 'layer_norm', 'from': 'conformer_9_ffmod_2_half_res_add'},
  'conv_1': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_source',
              'n_out': 32,
              'padding': 'same',
              'with_bias': True},
  'conv_1_pool': {'class': 'pool', 'from': 'conv_1', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv_2': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_1_pool',
              'n_out': 64,
              'padding': 'same',
              'strides': (2, 1),
              'with_bias': True},
  'conv_3': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_2',
              'n_out': 64,
              'padding': 'same',
              'strides': (2, 1),
              'with_bias': True},
  'conv_merged': {'axes': 'static', 'class': 'merge_dims', 'from': 'conv_3'},
  'conv_source': {'axis': 'F', 'class': 'split_dims', 'dims': (-1, 1), 'from': 'feature'},
  'encoder': {'class': 'reinterpret_data', 'from': 'conformer_12_output'},
  'feature': {'axis': 'F', 'class': 'slice', 'from': 'data', 'slice_end': 50, 'slice_start': 0, 'slice_step': None},
  'input_dropout': {'class': 'copy', 'dropout': 0, 'from': 'input_linear'},
  'input_linear': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conv_merged', 'n_out': 512, 'with_bias': False},
  'ivector_norm': {'class': 'eval', 'eval': 'tf.math.l2_normalize(source(0), axis=-1)', 'from': 'ivector_pooled'},
  'ivector_pooled': {'class': 'pool', 'from': 'ivectors', 'mode': 'max', 'padding': 'same', 'pool_size': (4,), 'trainable': False},
  'ivector_reinterpret': {'class': 'reinterpret_data', 'enforce_batch_major': True, 'from': 'ivector_norm', 'size_base': 'conformer_1_mhsa_mod_ln'},
  'ivector_transform': {'activation': None, 'class': 'linear', 'from': 'ivector_reinterpret', 'n_out': 512},
  'ivector_transform_2': {'activation': 'tanh', 'class': 'linear', 'from': 'ivector_reinterpret', 'n_out': 512},
  'ivector_weight': {'activation': 'sigmoid', 'class': 'activation', 'from': 'ivector_weight_wo_sigmoid'},
  'ivector_weight_wo_sigmoid': { 'class': 'eval',
                                 'eval': 'tf.reduce_sum(source(0, auto_convert=False) * source(1, auto_convert=False), axis=-1, keepdims=True)',
                                 'from': ['conformer_1_mhsa_mod_ln', 'ivector_transform_2'],
                                 'out_type': {'dim': 1, 'shape': (None, 1)}},
  'ivectors': {'axis': 'F', 'class': 'slice', 'from': 'data', 'slice_end': 250, 'slice_start': 50, 'slice_step': None},
  'mhsa_ivec_input': {'class': 'combine', 'from': ['conformer_1_mhsa_mod_ln', 'weighted_ivector'], 'kind': 'add'},
  'output': { 'class': 'subnetwork',
              'from': 'encoder',
              'subnetwork': { 'output': {'class': 'copy', 'from': 'rec'},
                              'rec': { 'class': 'subnetwork',
                                       'from': 'data',
                                       'subnetwork': { 'ILM_joint': { 'L2': 5e-06,
                                                                      'activation': 'tanh',
                                                                      'class': 'linear',
                                                                      'dropout': 0,
                                                                      'from': 'zero_encoder',
                                                                      'n_out': 1024,
                                                                      'reuse_params': 'joint_encoding'},
                                                       'ILM_output': { 'class': 'softmax',
                                                                       'from': 'ILM_joint',
                                                                       'is_output_layer': True,
                                                                       'n_out': 79,
                                                                       'reuse_params': 'output'},
                                                       'all_context': { 'as_batch': True,
                                                                        'class': 'constant',
                                                                        'dtype': 'int32',
                                                                        'out_type': {'dim': 79, 'sparse': True},
                                                                        'value': [ 80,
                                                                                   1,
                                                                                   2,
                                                                                   3,
                                                                                   4,
                                                                                   5,
                                                                                   6,
                                                                                   7,
                                                                                   8,
                                                                                   9,
                                                                                   10,
                                                                                   11,
                                                                                   12,
                                                                                   13,
                                                                                   14,
                                                                                   15,
                                                                                   16,
                                                                                   17,
                                                                                   18,
                                                                                   19,
                                                                                   20,
                                                                                   21,
                                                                                   22,
                                                                                   23,
                                                                                   24,
                                                                                   25,
                                                                                   26,
                                                                                   27,
                                                                                   28,
                                                                                   29,
                                                                                   30,
                                                                                   31,
                                                                                   32,
                                                                                   33,
                                                                                   34,
                                                                                   35,
                                                                                   36,
                                                                                   37,
                                                                                   38,
                                                                                   39,
                                                                                   40,
                                                                                   41,
                                                                                   42,
                                                                                   43,
                                                                                   44,
                                                                                   45,
                                                                                   46,
                                                                                   47,
                                                                                   48,
                                                                                   49,
                                                                                   50,
                                                                                   51,
                                                                                   52,
                                                                                   53,
                                                                                   54,
                                                                                   55,
                                                                                   56,
                                                                                   57,
                                                                                   58,
                                                                                   59,
                                                                                   60,
                                                                                   61,
                                                                                   62,
                                                                                   63,
                                                                                   64,
                                                                                   65,
                                                                                   66,
                                                                                   67,
                                                                                   68,
                                                                                   69,
                                                                                   70,
                                                                                   71,
                                                                                   72,
                                                                                   73,
                                                                                   74,
                                                                                   75,
                                                                                   76,
                                                                                   77,
                                                                                   78],
                                                                        'with_batch_dim': True},
                                                       'embedding': { 'L2': 5e-06,
                                                                      'activation': None,
                                                                      'class': 'linear',
                                                                      'from': 'all_context',
                                                                      'initial_output': None,
                                                                      'n_out': 128,
                                                                      'safe_embedding': True,
                                                                      'with_bias': False},
                                                       'joint_encoding': { 'L2': 5e-06,
                                                                           'activation': 'tanh',
                                                                           'class': 'linear',
                                                                           'dropout': 0,
                                                                           'from': ['tile_encoder', 'label_lm_2'],
                                                                           'n_out': 1024},
                                                       'label_lm_1': { 'L2': 5e-06,
                                                                       'activation': 'tanh',
                                                                       'class': 'linear',
                                                                       'dropout': 0,
                                                                       'from': ['embedding'],
                                                                       'n_out': 640},
                                                       'label_lm_2': { 'L2': 5e-06,
                                                                       'activation': 'tanh',
                                                                       'class': 'linear',
                                                                       'dropout': 0,
                                                                       'from': 'label_lm_1',
                                                                       'n_out': 640},
                                                       'output': {'class': 'softmax', 'from': 'joint_encoding', 'is_output_layer': True, 'n_out': 79},
                                                       'output_norm_ILM': { 'class': 'eval',
                                                                            'eval': "self.network.get_config().typed_value('subtract_ILM')(source(0, "
                                                                                    'auto_convert=False, enforce_batch_major=True), source(1, '
                                                                                    'auto_convert=False, enforce_batch_major=True), scale=0.200000)',
                                                                            'from': ['output', 'ILM_output'],
                                                                            'is_output_layer': True,
                                                                            'n_out': 79},
                                                       'tile_encoder': { 'class': 'eval',
                                                                         'eval': 'tf.tile(source(0), [79, 1, 1])',
                                                                         'from': 'base:base:encoder'},
                                                       'zero_encoder': { 'axes': 'F',
                                                                         'class': 'pad',
                                                                         'from': 'label_lm_2',
                                                                         'mode': 'constant',
                                                                         'padding': (512, 0),
                                                                         'value': 0}}}}},
  'output_precompute': { 'class': 'eval',
                         'eval': "self.network.get_config().typed_value('final_output')(source(0, auto_convert=False, enforce_batch_major=True), 79)",
                         'from': 'output/rec/output_norm_ILM',
                         'is_output_layer': True,
                         'out_type': {'dim': 6241, 'shape': (None, 6241)}},
  'weighted_ivector': {'class': 'combine', 'from': ['ivector_transform', 'ivector_weight'], 'kind': 'mul'}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 20
newbob_multi_update_interval = 1
num_inputs = 250
num_outputs = 79
optimizer_epsilon = 1e-08
pretrain = 'default'
start_batch = 'auto'
start_epoch = 'auto'
target = 'classes'
truncation = -1
update_on_device = True
use_tensorflow = True
window = 1
config = {}

locals().update(**config)

# broadcast ILM prob to full T-dim transducer prob
def subtract_ILM(transducer_prob, lm_prob, scale=0.3):
  import tensorflow as tf
  sb = lm_prob[:, :1] # (B, 1)
  lm_label = lm_prob[:, 1:] # (B, V-1)
  norm = tf.pow(lm_label / (1.0 - sb), scale)
  norm = tf.concat([tf.ones_like(sb), norm], axis=-1) 
  norm = tf.expand_dims(norm, axis=1) # (B, 1, V)
  return transducer_prob / norm # (B, T, V)

# reshape output (B=V, T, V) to (1, T, V^2) + log_prob
def final_output(output, num_classes, apply_log=True):
  import tensorflow as tf
  x = tf.transpose(output, perm=[0, 2, 1]) # (V, V, T)
  x = tf.reshape(x, [1, num_classes**2, -1]) # (1, V^2, T)
  x = tf.transpose(x, perm=[0, 2, 1]) # (1, T, V^2)
  if apply_log:
    from TFUtil import safe_log
    return safe_log(x)
  else:
    return x


