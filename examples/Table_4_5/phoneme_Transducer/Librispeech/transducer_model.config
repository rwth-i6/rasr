#!rnn.py
import sys
sys.setrecursionlimit(4000)

accum_grad_multiple_step = 8
batch_size = 2000
batching = 'random'
cache_size = '0'
cleanup_old_models = {'keep': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}
dev = None
device = 'gpu'
gradient_clip = 0
gradient_noise = 0
learning_rate = 1e-05
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
learning_rate_file = 'learning_rates'
log = ['./crnn.log']
log_verbosity = 3
max_seq_length = {'classes': 408, 'nbest_classes': 190}
max_seqs = 128
min_learning_rate = 1e-05
model = '/u/zhou/asr-exps/librispeech/2021-01-22_phoneme-transducer/work/crnn/custom_sprint_training/CustomCRNNSprintTrainingJob.XLFvR0vNHEXp/output/models/epoch'
multiprocessing = True
nadam = True
network = { 'conformer_10_conv_mod_bn': { 'class': 'batch_norm',
                                'delay_sample_update': True,
                                'epsilon': 1e-05,
                                'from': 'conformer_10_conv_mod_depthwise_conv',
                                'momentum': 0.0,
                                'update_sample_only_in_training': True,
                                'use_sample': 1.0},
  'conformer_10_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_10_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_10_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_10_conv_mod_pointwise_conv_2'},
  'conformer_10_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_10_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_10_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_10_ffmod_1_half_res_add'},
  'conformer_10_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_10_conv_mod_ln', 'n_out': 1024},
  'conformer_10_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_10_conv_mod_swish', 'n_out': 512},
  'conformer_10_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_10_conv_mod_dropout', 'conformer_10_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_10_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_10_conv_mod_bn'},
  'conformer_10_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_10_ffmod_1_dropout_linear'},
  'conformer_10_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.2,
                                           'from': 'conformer_10_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_10_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_10_ffmod_1_dropout', 'conformer_9_output']},
  'conformer_10_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_10_ffmod_1_ln', 'n_out': 2048},
  'conformer_10_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_9_output'},
  'conformer_10_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_10_ffmod_2_dropout_linear'},
  'conformer_10_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.2,
                                           'from': 'conformer_10_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_10_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_10_ffmod_2_dropout', 'conformer_10_mhsa_mod_res_add']},
  'conformer_10_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_10_ffmod_2_ln', 'n_out': 2048},
  'conformer_10_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_10_mhsa_mod_res_add'},
  'conformer_10_mhsa_mod_att_linear': { 'L2': 5e-06,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_10_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_10_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_10_mhsa_mod_att_linear'},
  'conformer_10_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_10_conv_mod_res_add'},
  'conformer_10_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_10_mhsa_mod_ln', 'n_out': 64},
  'conformer_10_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_10_mhsa_mod_dropout', 'conformer_10_conv_mod_res_add'], 'kind': 'add'},
  'conformer_10_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                            'class': 'self_attention',
                                            'from': 'conformer_10_mhsa_mod_ln',
                                            'key_shift': 'conformer_10_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_10_output': {'class': 'layer_norm', 'from': 'conformer_10_ffmod_2_half_res_add'},
  'conformer_11_conv_mod_bn': { 'class': 'batch_norm',
                                'delay_sample_update': True,
                                'epsilon': 1e-05,
                                'from': 'conformer_11_conv_mod_depthwise_conv',
                                'momentum': 0.0,
                                'update_sample_only_in_training': True,
                                'use_sample': 1.0},
  'conformer_11_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_11_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_11_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_11_conv_mod_pointwise_conv_2'},
  'conformer_11_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_11_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_11_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_11_ffmod_1_half_res_add'},
  'conformer_11_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_11_conv_mod_ln', 'n_out': 1024},
  'conformer_11_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_11_conv_mod_swish', 'n_out': 512},
  'conformer_11_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_11_conv_mod_dropout', 'conformer_11_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_11_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_11_conv_mod_bn'},
  'conformer_11_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_11_ffmod_1_dropout_linear'},
  'conformer_11_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.2,
                                           'from': 'conformer_11_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_11_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_11_ffmod_1_dropout', 'conformer_10_output']},
  'conformer_11_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_11_ffmod_1_ln', 'n_out': 2048},
  'conformer_11_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_10_output'},
  'conformer_11_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_11_ffmod_2_dropout_linear'},
  'conformer_11_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.2,
                                           'from': 'conformer_11_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_11_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_11_ffmod_2_dropout', 'conformer_11_mhsa_mod_res_add']},
  'conformer_11_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_11_ffmod_2_ln', 'n_out': 2048},
  'conformer_11_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_11_mhsa_mod_res_add'},
  'conformer_11_mhsa_mod_att_linear': { 'L2': 5e-06,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_11_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_11_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_11_mhsa_mod_att_linear'},
  'conformer_11_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_11_conv_mod_res_add'},
  'conformer_11_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_11_mhsa_mod_ln', 'n_out': 64},
  'conformer_11_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_11_mhsa_mod_dropout', 'conformer_11_conv_mod_res_add'], 'kind': 'add'},
  'conformer_11_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                            'class': 'self_attention',
                                            'from': 'conformer_11_mhsa_mod_ln',
                                            'key_shift': 'conformer_11_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_11_output': {'class': 'layer_norm', 'from': 'conformer_11_ffmod_2_half_res_add'},
  'conformer_12_conv_mod_bn': { 'class': 'batch_norm',
                                'delay_sample_update': True,
                                'epsilon': 1e-05,
                                'from': 'conformer_12_conv_mod_depthwise_conv',
                                'momentum': 0.0,
                                'update_sample_only_in_training': True,
                                'use_sample': 1.0},
  'conformer_12_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (32,),
                                            'from': 'conformer_12_conv_mod_glu',
                                            'groups': 512,
                                            'n_out': 512,
                                            'padding': 'same',
                                            'with_bias': True},
  'conformer_12_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_12_conv_mod_pointwise_conv_2'},
  'conformer_12_conv_mod_glu': { 'activation': None,
                                 'class': 'gating',
                                 'from': 'conformer_12_conv_mod_pointwise_conv_1',
                                 'gate_activation': 'sigmoid'},
  'conformer_12_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_12_ffmod_1_half_res_add'},
  'conformer_12_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_12_conv_mod_ln', 'n_out': 1024},
  'conformer_12_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_12_conv_mod_swish', 'n_out': 512},
  'conformer_12_conv_mod_res_add': { 'class': 'combine',
                                     'from': ['conformer_12_conv_mod_dropout', 'conformer_12_ffmod_1_half_res_add'],
                                     'kind': 'add'},
  'conformer_12_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_12_conv_mod_bn'},
  'conformer_12_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_12_ffmod_1_dropout_linear'},
  'conformer_12_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.2,
                                           'from': 'conformer_12_ffmod_1_linear_swish',
                                           'n_out': 512},
  'conformer_12_ffmod_1_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_12_ffmod_1_dropout', 'conformer_11_output']},
  'conformer_12_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_12_ffmod_1_ln', 'n_out': 2048},
  'conformer_12_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_11_output'},
  'conformer_12_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_12_ffmod_2_dropout_linear'},
  'conformer_12_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'linear',
                                           'dropout': 0.2,
                                           'from': 'conformer_12_ffmod_2_linear_swish',
                                           'n_out': 512},
  'conformer_12_ffmod_2_half_res_add': { 'class': 'eval',
                                         'eval': '0.5 * source(0) + source(1)',
                                         'from': ['conformer_12_ffmod_2_dropout', 'conformer_12_mhsa_mod_res_add']},
  'conformer_12_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_12_ffmod_2_ln', 'n_out': 2048},
  'conformer_12_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_12_mhsa_mod_res_add'},
  'conformer_12_mhsa_mod_att_linear': { 'L2': 5e-06,
                                        'activation': None,
                                        'class': 'linear',
                                        'from': 'conformer_12_mhsa_mod_self_attention',
                                        'n_out': 512,
                                        'with_bias': False},
  'conformer_12_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_12_mhsa_mod_att_linear'},
  'conformer_12_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_12_conv_mod_res_add'},
  'conformer_12_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_12_mhsa_mod_ln', 'n_out': 64},
  'conformer_12_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_12_mhsa_mod_dropout', 'conformer_12_conv_mod_res_add'], 'kind': 'add'},
  'conformer_12_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                            'class': 'self_attention',
                                            'from': 'conformer_12_mhsa_mod_ln',
                                            'key_shift': 'conformer_12_mhsa_mod_relpos_encoding',
                                            'n_out': 512,
                                            'num_heads': 8,
                                            'total_key_dim': 512},
  'conformer_12_output': {'class': 'layer_norm', 'from': 'conformer_12_ffmod_2_half_res_add'},
  'conformer_1_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_1_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_1_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_1_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_1_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_1_conv_mod_pointwise_conv_2'},
  'conformer_1_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_1_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_1_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_1_ffmod_1_half_res_add'},
  'conformer_1_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_1_conv_mod_ln', 'n_out': 1024},
  'conformer_1_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_1_conv_mod_swish', 'n_out': 512},
  'conformer_1_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_1_conv_mod_dropout', 'conformer_1_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_1_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_1_conv_mod_bn'},
  'conformer_1_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_1_ffmod_1_dropout_linear'},
  'conformer_1_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_1_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_1_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_1_ffmod_1_dropout', 'input_dropout']},
  'conformer_1_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_1_ffmod_1_ln', 'n_out': 2048},
  'conformer_1_ffmod_1_ln': {'class': 'layer_norm', 'from': 'input_dropout'},
  'conformer_1_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_1_ffmod_2_dropout_linear'},
  'conformer_1_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_1_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_1_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_1_ffmod_2_dropout', 'conformer_1_mhsa_mod_res_add']},
  'conformer_1_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_1_ffmod_2_ln', 'n_out': 2048},
  'conformer_1_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_1_mhsa_mod_res_add'},
  'conformer_1_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_1_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_1_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_1_mhsa_mod_att_linear'},
  'conformer_1_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_1_conv_mod_res_add'},
  'conformer_1_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_1_mhsa_mod_ln', 'n_out': 64},
  'conformer_1_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_1_mhsa_mod_dropout', 'conformer_1_conv_mod_res_add'], 'kind': 'add'},
  'conformer_1_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_1_mhsa_mod_ln',
                                           'key_shift': 'conformer_1_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_1_output': {'class': 'layer_norm', 'from': 'conformer_1_ffmod_2_half_res_add'},
  'conformer_2_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_2_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_2_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_2_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_2_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_2_conv_mod_pointwise_conv_2'},
  'conformer_2_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_2_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_2_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_2_ffmod_1_half_res_add'},
  'conformer_2_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_2_conv_mod_ln', 'n_out': 1024},
  'conformer_2_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_2_conv_mod_swish', 'n_out': 512},
  'conformer_2_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_2_conv_mod_dropout', 'conformer_2_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_2_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_2_conv_mod_bn'},
  'conformer_2_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_2_ffmod_1_dropout_linear'},
  'conformer_2_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_2_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_2_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_2_ffmod_1_dropout', 'conformer_1_output']},
  'conformer_2_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_2_ffmod_1_ln', 'n_out': 2048},
  'conformer_2_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_1_output'},
  'conformer_2_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_2_ffmod_2_dropout_linear'},
  'conformer_2_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_2_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_2_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_2_ffmod_2_dropout', 'conformer_2_mhsa_mod_res_add']},
  'conformer_2_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_2_ffmod_2_ln', 'n_out': 2048},
  'conformer_2_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_2_mhsa_mod_res_add'},
  'conformer_2_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_2_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_2_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_2_mhsa_mod_att_linear'},
  'conformer_2_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_2_conv_mod_res_add'},
  'conformer_2_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_2_mhsa_mod_ln', 'n_out': 64},
  'conformer_2_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_2_mhsa_mod_dropout', 'conformer_2_conv_mod_res_add'], 'kind': 'add'},
  'conformer_2_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_2_mhsa_mod_ln',
                                           'key_shift': 'conformer_2_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_2_output': {'class': 'layer_norm', 'from': 'conformer_2_ffmod_2_half_res_add'},
  'conformer_3_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_3_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_3_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_3_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_3_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_3_conv_mod_pointwise_conv_2'},
  'conformer_3_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_3_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_3_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_3_ffmod_1_half_res_add'},
  'conformer_3_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_3_conv_mod_ln', 'n_out': 1024},
  'conformer_3_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_3_conv_mod_swish', 'n_out': 512},
  'conformer_3_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_3_conv_mod_dropout', 'conformer_3_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_3_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_3_conv_mod_bn'},
  'conformer_3_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_3_ffmod_1_dropout_linear'},
  'conformer_3_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_3_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_3_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_3_ffmod_1_dropout', 'conformer_2_output']},
  'conformer_3_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_3_ffmod_1_ln', 'n_out': 2048},
  'conformer_3_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_2_output'},
  'conformer_3_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_3_ffmod_2_dropout_linear'},
  'conformer_3_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_3_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_3_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_3_ffmod_2_dropout', 'conformer_3_mhsa_mod_res_add']},
  'conformer_3_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_3_ffmod_2_ln', 'n_out': 2048},
  'conformer_3_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_3_mhsa_mod_res_add'},
  'conformer_3_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_3_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_3_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_3_mhsa_mod_att_linear'},
  'conformer_3_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_3_conv_mod_res_add'},
  'conformer_3_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_3_mhsa_mod_ln', 'n_out': 64},
  'conformer_3_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_3_mhsa_mod_dropout', 'conformer_3_conv_mod_res_add'], 'kind': 'add'},
  'conformer_3_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_3_mhsa_mod_ln',
                                           'key_shift': 'conformer_3_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_3_output': {'class': 'layer_norm', 'from': 'conformer_3_ffmod_2_half_res_add'},
  'conformer_4_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_4_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_4_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_4_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_4_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_4_conv_mod_pointwise_conv_2'},
  'conformer_4_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_4_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_4_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_4_ffmod_1_half_res_add'},
  'conformer_4_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_4_conv_mod_ln', 'n_out': 1024},
  'conformer_4_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_4_conv_mod_swish', 'n_out': 512},
  'conformer_4_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_4_conv_mod_dropout', 'conformer_4_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_4_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_4_conv_mod_bn'},
  'conformer_4_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_4_ffmod_1_dropout_linear'},
  'conformer_4_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_4_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_4_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_4_ffmod_1_dropout', 'conformer_3_output']},
  'conformer_4_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_4_ffmod_1_ln', 'n_out': 2048},
  'conformer_4_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_3_output'},
  'conformer_4_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_4_ffmod_2_dropout_linear'},
  'conformer_4_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_4_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_4_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_4_ffmod_2_dropout', 'conformer_4_mhsa_mod_res_add']},
  'conformer_4_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_4_ffmod_2_ln', 'n_out': 2048},
  'conformer_4_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_4_mhsa_mod_res_add'},
  'conformer_4_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_4_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_4_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_4_mhsa_mod_att_linear'},
  'conformer_4_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_4_conv_mod_res_add'},
  'conformer_4_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_4_mhsa_mod_ln', 'n_out': 64},
  'conformer_4_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_4_mhsa_mod_dropout', 'conformer_4_conv_mod_res_add'], 'kind': 'add'},
  'conformer_4_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_4_mhsa_mod_ln',
                                           'key_shift': 'conformer_4_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_4_output': {'class': 'layer_norm', 'from': 'conformer_4_ffmod_2_half_res_add'},
  'conformer_5_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_5_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_5_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_5_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_5_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_5_conv_mod_pointwise_conv_2'},
  'conformer_5_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_5_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_5_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_5_ffmod_1_half_res_add'},
  'conformer_5_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_5_conv_mod_ln', 'n_out': 1024},
  'conformer_5_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_5_conv_mod_swish', 'n_out': 512},
  'conformer_5_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_5_conv_mod_dropout', 'conformer_5_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_5_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_5_conv_mod_bn'},
  'conformer_5_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_5_ffmod_1_dropout_linear'},
  'conformer_5_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_5_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_5_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_5_ffmod_1_dropout', 'conformer_4_output']},
  'conformer_5_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_5_ffmod_1_ln', 'n_out': 2048},
  'conformer_5_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_4_output'},
  'conformer_5_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_5_ffmod_2_dropout_linear'},
  'conformer_5_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_5_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_5_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_5_ffmod_2_dropout', 'conformer_5_mhsa_mod_res_add']},
  'conformer_5_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_5_ffmod_2_ln', 'n_out': 2048},
  'conformer_5_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_5_mhsa_mod_res_add'},
  'conformer_5_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_5_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_5_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_5_mhsa_mod_att_linear'},
  'conformer_5_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_5_conv_mod_res_add'},
  'conformer_5_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_5_mhsa_mod_ln', 'n_out': 64},
  'conformer_5_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_5_mhsa_mod_dropout', 'conformer_5_conv_mod_res_add'], 'kind': 'add'},
  'conformer_5_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_5_mhsa_mod_ln',
                                           'key_shift': 'conformer_5_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_5_output': {'class': 'layer_norm', 'from': 'conformer_5_ffmod_2_half_res_add'},
  'conformer_6_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_6_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_6_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_6_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_6_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_6_conv_mod_pointwise_conv_2'},
  'conformer_6_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_6_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_6_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_6_ffmod_1_half_res_add'},
  'conformer_6_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_6_conv_mod_ln', 'n_out': 1024},
  'conformer_6_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_6_conv_mod_swish', 'n_out': 512},
  'conformer_6_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_6_conv_mod_dropout', 'conformer_6_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_6_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_6_conv_mod_bn'},
  'conformer_6_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_6_ffmod_1_dropout_linear'},
  'conformer_6_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_6_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_6_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_6_ffmod_1_dropout', 'conformer_5_output']},
  'conformer_6_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_6_ffmod_1_ln', 'n_out': 2048},
  'conformer_6_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_5_output'},
  'conformer_6_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_6_ffmod_2_dropout_linear'},
  'conformer_6_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_6_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_6_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_6_ffmod_2_dropout', 'conformer_6_mhsa_mod_res_add']},
  'conformer_6_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_6_ffmod_2_ln', 'n_out': 2048},
  'conformer_6_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_6_mhsa_mod_res_add'},
  'conformer_6_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_6_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_6_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_6_mhsa_mod_att_linear'},
  'conformer_6_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_6_conv_mod_res_add'},
  'conformer_6_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_6_mhsa_mod_ln', 'n_out': 64},
  'conformer_6_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_6_mhsa_mod_dropout', 'conformer_6_conv_mod_res_add'], 'kind': 'add'},
  'conformer_6_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_6_mhsa_mod_ln',
                                           'key_shift': 'conformer_6_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_6_output': {'class': 'layer_norm', 'from': 'conformer_6_ffmod_2_half_res_add'},
  'conformer_7_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_7_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_7_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_7_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_7_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_7_conv_mod_pointwise_conv_2'},
  'conformer_7_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_7_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_7_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_7_ffmod_1_half_res_add'},
  'conformer_7_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_7_conv_mod_ln', 'n_out': 1024},
  'conformer_7_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_7_conv_mod_swish', 'n_out': 512},
  'conformer_7_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_7_conv_mod_dropout', 'conformer_7_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_7_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_7_conv_mod_bn'},
  'conformer_7_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_7_ffmod_1_dropout_linear'},
  'conformer_7_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_7_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_7_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_7_ffmod_1_dropout', 'conformer_6_output']},
  'conformer_7_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_7_ffmod_1_ln', 'n_out': 2048},
  'conformer_7_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_6_output'},
  'conformer_7_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_7_ffmod_2_dropout_linear'},
  'conformer_7_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_7_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_7_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_7_ffmod_2_dropout', 'conformer_7_mhsa_mod_res_add']},
  'conformer_7_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_7_ffmod_2_ln', 'n_out': 2048},
  'conformer_7_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_7_mhsa_mod_res_add'},
  'conformer_7_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_7_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_7_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_7_mhsa_mod_att_linear'},
  'conformer_7_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_7_conv_mod_res_add'},
  'conformer_7_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_7_mhsa_mod_ln', 'n_out': 64},
  'conformer_7_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_7_mhsa_mod_dropout', 'conformer_7_conv_mod_res_add'], 'kind': 'add'},
  'conformer_7_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_7_mhsa_mod_ln',
                                           'key_shift': 'conformer_7_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_7_output': {'class': 'layer_norm', 'from': 'conformer_7_ffmod_2_half_res_add'},
  'conformer_8_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_8_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_8_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_8_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_8_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_8_conv_mod_pointwise_conv_2'},
  'conformer_8_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_8_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_8_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_8_ffmod_1_half_res_add'},
  'conformer_8_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_8_conv_mod_ln', 'n_out': 1024},
  'conformer_8_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_8_conv_mod_swish', 'n_out': 512},
  'conformer_8_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_8_conv_mod_dropout', 'conformer_8_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_8_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_8_conv_mod_bn'},
  'conformer_8_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_8_ffmod_1_dropout_linear'},
  'conformer_8_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_8_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_8_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_8_ffmod_1_dropout', 'conformer_7_output']},
  'conformer_8_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_8_ffmod_1_ln', 'n_out': 2048},
  'conformer_8_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_7_output'},
  'conformer_8_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_8_ffmod_2_dropout_linear'},
  'conformer_8_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_8_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_8_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_8_ffmod_2_dropout', 'conformer_8_mhsa_mod_res_add']},
  'conformer_8_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_8_ffmod_2_ln', 'n_out': 2048},
  'conformer_8_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_8_mhsa_mod_res_add'},
  'conformer_8_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_8_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_8_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_8_mhsa_mod_att_linear'},
  'conformer_8_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_8_conv_mod_res_add'},
  'conformer_8_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_8_mhsa_mod_ln', 'n_out': 64},
  'conformer_8_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_8_mhsa_mod_dropout', 'conformer_8_conv_mod_res_add'], 'kind': 'add'},
  'conformer_8_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_8_mhsa_mod_ln',
                                           'key_shift': 'conformer_8_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_8_output': {'class': 'layer_norm', 'from': 'conformer_8_ffmod_2_half_res_add'},
  'conformer_9_conv_mod_bn': { 'class': 'batch_norm',
                               'delay_sample_update': True,
                               'epsilon': 1e-05,
                               'from': 'conformer_9_conv_mod_depthwise_conv',
                               'momentum': 0.0,
                               'update_sample_only_in_training': True,
                               'use_sample': 1.0},
  'conformer_9_conv_mod_depthwise_conv': { 'L2': 5e-06,
                                           'activation': None,
                                           'class': 'conv',
                                           'filter_size': (32,),
                                           'from': 'conformer_9_conv_mod_glu',
                                           'groups': 512,
                                           'n_out': 512,
                                           'padding': 'same',
                                           'with_bias': True},
  'conformer_9_conv_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_9_conv_mod_pointwise_conv_2'},
  'conformer_9_conv_mod_glu': {'activation': None, 'class': 'gating', 'from': 'conformer_9_conv_mod_pointwise_conv_1', 'gate_activation': 'sigmoid'},
  'conformer_9_conv_mod_ln': {'class': 'layer_norm', 'from': 'conformer_9_ffmod_1_half_res_add'},
  'conformer_9_conv_mod_pointwise_conv_1': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_9_conv_mod_ln', 'n_out': 1024},
  'conformer_9_conv_mod_pointwise_conv_2': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conformer_9_conv_mod_swish', 'n_out': 512},
  'conformer_9_conv_mod_res_add': {'class': 'combine', 'from': ['conformer_9_conv_mod_dropout', 'conformer_9_ffmod_1_half_res_add'], 'kind': 'add'},
  'conformer_9_conv_mod_swish': {'activation': 'swish', 'class': 'activation', 'from': 'conformer_9_conv_mod_bn'},
  'conformer_9_ffmod_1_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_9_ffmod_1_dropout_linear'},
  'conformer_9_ffmod_1_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_9_ffmod_1_linear_swish',
                                          'n_out': 512},
  'conformer_9_ffmod_1_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_9_ffmod_1_dropout', 'conformer_8_output']},
  'conformer_9_ffmod_1_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_9_ffmod_1_ln', 'n_out': 2048},
  'conformer_9_ffmod_1_ln': {'class': 'layer_norm', 'from': 'conformer_8_output'},
  'conformer_9_ffmod_2_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_9_ffmod_2_dropout_linear'},
  'conformer_9_ffmod_2_dropout_linear': { 'L2': 5e-06,
                                          'activation': None,
                                          'class': 'linear',
                                          'dropout': 0.2,
                                          'from': 'conformer_9_ffmod_2_linear_swish',
                                          'n_out': 512},
  'conformer_9_ffmod_2_half_res_add': { 'class': 'eval',
                                        'eval': '0.5 * source(0) + source(1)',
                                        'from': ['conformer_9_ffmod_2_dropout', 'conformer_9_mhsa_mod_res_add']},
  'conformer_9_ffmod_2_linear_swish': {'L2': 5e-06, 'activation': 'swish', 'class': 'linear', 'from': 'conformer_9_ffmod_2_ln', 'n_out': 2048},
  'conformer_9_ffmod_2_ln': {'class': 'layer_norm', 'from': 'conformer_9_mhsa_mod_res_add'},
  'conformer_9_mhsa_mod_att_linear': { 'L2': 5e-06,
                                       'activation': None,
                                       'class': 'linear',
                                       'from': 'conformer_9_mhsa_mod_self_attention',
                                       'n_out': 512,
                                       'with_bias': False},
  'conformer_9_mhsa_mod_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'conformer_9_mhsa_mod_att_linear'},
  'conformer_9_mhsa_mod_ln': {'class': 'layer_norm', 'from': 'conformer_9_conv_mod_res_add'},
  'conformer_9_mhsa_mod_relpos_encoding': {'class': 'relative_positional_encoding', 'clipping': 32, 'from': 'conformer_9_mhsa_mod_ln', 'n_out': 64},
  'conformer_9_mhsa_mod_res_add': {'class': 'combine', 'from': ['conformer_9_mhsa_mod_dropout', 'conformer_9_conv_mod_res_add'], 'kind': 'add'},
  'conformer_9_mhsa_mod_self_attention': { 'attention_dropout': 0.2,
                                           'class': 'self_attention',
                                           'from': 'conformer_9_mhsa_mod_ln',
                                           'key_shift': 'conformer_9_mhsa_mod_relpos_encoding',
                                           'n_out': 512,
                                           'num_heads': 8,
                                           'total_key_dim': 512},
  'conformer_9_output': {'class': 'layer_norm', 'from': 'conformer_9_ffmod_2_half_res_add'},
  'conv_1': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_source',
              'n_out': 32,
              'padding': 'same',
              'with_bias': True},
  'conv_1_pool': {'class': 'pool', 'from': 'conv_1', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv_2': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_1_pool',
              'n_out': 64,
              'padding': 'same',
              'strides': (2, 1),
              'with_bias': True},
  'conv_3': { 'L2': 0.01,
              'activation': 'swish',
              'class': 'conv',
              'filter_size': (3, 3),
              'from': 'conv_2',
              'n_out': 64,
              'padding': 'same',
              'strides': (2, 1),
              'with_bias': True},
  'conv_merged': {'axes': 'static', 'class': 'merge_dims', 'from': 'conv_3'},
  'conv_source': {'axis': 'F', 'class': 'split_dims', 'dims': (-1, 1), 'from': ['data']},
  'encoder': {'class': 'reinterpret_data', 'from': 'conformer_12_output', 'size_base': 'data:classes'},
  'input_dropout': {'class': 'copy', 'dropout': 0.2, 'from': 'input_linear'},
  'input_linear': {'L2': 5e-06, 'activation': None, 'class': 'linear', 'from': 'conv_merged', 'n_out': 512, 'with_bias': False},
  'mask_flag': {'class': 'compare', 'from': ['data:classes'], 'kind': 'not_equal', 'value': 0},
  'mask_label': {'class': 'masked_computation', 'from': ['data:classes'], 'mask': 'mask_flag', 'unit': {'class': 'copy'}},
  'nbest_MBR_loss': { 'L2': 5e-06,
                      'blank_label': 0,
                      'class': 'iterative_nbest_mbr',
                      'dropout': 0.2,
                      'from': ['encoder', 'nbest_label_lm_2', 'data:nbest_classes', 'data:nbest_score', 'data:nbest_risk'],
                      'loss': 'as_is',
                      'nbest': 4,
                      'renorm_scale': 1.43,
                      'reuse_joint': ('_joint', 1024, 'tanh'),
                      'reuse_output': ('_output', 79),
                      'reuse_params': { 'map': { 'W_joint': 'output/rec/joint_encoding',
                                                 'W_output': 'output/rec/output',
                                                 'b_joint': 'output/rec/joint_encoding',
                                                 'b_output': 'output/rec/output'}},
                      'rnnt_loss_scale': 0.1,
                      'use_nbest_score': True},
  'nbest_embedding': { 'L2': 5e-06,
                       'activation': None,
                       'class': 'linear',
                       'from': 'data:nbest_classes',
                       'n_out': 128,
                       'reuse_params': 'output/rec/embedding',
                       'with_bias': False},
  'nbest_label_lm_1': { 'L2': 5e-06,
                        'activation': 'tanh',
                        'class': 'linear',
                        'dropout': 0.2,
                        'from': ['nbest_mask_embedding'],
                        'n_out': 640,
                        'reuse_params': 'output/rec/label_lm_1'},
  'nbest_label_lm_2': { 'L2': 5e-06,
                        'activation': 'tanh',
                        'class': 'linear',
                        'dropout': 0.2,
                        'from': 'nbest_label_lm_1',
                        'n_out': 640,
                        'reuse_params': 'output/rec/label_lm_2'},
  'nbest_mask_embedding': {'axes': 'T', 'class': 'pad', 'from': 'nbest_embedding', 'mode': 'constant', 'padding': (1, 0), 'value': 0},
  'output': { 'class': 'subnetwork',
              'from': 'encoder',
              'subnetwork': { 'output': {'class': 'copy', 'from': 'rec'},
                              'rec': { 'class': 'subnetwork',
                                       'from': 'data',
                                       'subnetwork': { 'compress_concat': {'class': 'compressed_concat', 'from': ['base:base:encoder', 'label_lm_2']},
                                                       'embedding': { 'L2': 5e-06,
                                                                      'activation': None,
                                                                      'class': 'linear',
                                                                      'from': 'base:base:mask_label',
                                                                      'n_out': 128,
                                                                      'with_bias': False},
                                                       'joint_encoding': { 'L2': 5e-06,
                                                                           'activation': 'tanh',
                                                                           'class': 'linear',
                                                                           'dropout': 0.2,
                                                                           'from': ['compress_concat'],
                                                                           'n_out': 1024,
                                                                           'out_type': { 'batch_dim_axis': None,
                                                                                         'shape': (None, 1024),
                                                                                         'time_dim_axis': 0}},
                                                       'label_lm_1': { 'L2': 5e-06,
                                                                       'activation': 'tanh',
                                                                       'class': 'linear',
                                                                       'dropout': 0.2,
                                                                       'from': ['mask_embedding'],
                                                                       'n_out': 640},
                                                       'label_lm_2': { 'L2': 5e-06,
                                                                       'activation': 'tanh',
                                                                       'class': 'linear',
                                                                       'dropout': 0.2,
                                                                       'from': 'label_lm_1',
                                                                       'n_out': 640},
                                                       'mask_embedding': { 'axes': 'T',
                                                                           'class': 'pad',
                                                                           'from': 'embedding',
                                                                           'mode': 'constant',
                                                                           'padding': (1, 0),
                                                                           'value': 0},
                                                       'output': { 'activation': None,
                                                                   'class': 'linear',
                                                                   'from': 'joint_encoding',
                                                                   'n_out': 79,
                                                                   'out_type': {'batch_dim_axis': None, 'shape': (None, 79), 'time_dim_axis': 0}},
                                                       'rnnt_loss': { 'class': 'eval',
                                                                      'eval': "self.network.get_config().typed_value('rnnt_loss')(source, "
                                                                              'blank_label=0)',
                                                                      'from': ['output', 'base:base:mask_label', 'base:base:encoder'],
                                                                      'is_output_layer': True,
                                                                      'out_type': { 'batch_dim_axis': 0,
                                                                                    'dim': None,
                                                                                    'shape': (),
                                                                                    'time_dim_axis': None}}}}}}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 20
newbob_multi_update_interval = 1
num_epochs = 20
num_inputs = 50
num_outputs = { 'classes': 79,
  'nbest_classes': {'dim': 79, 'dtype': 'int32', 'sparse': True},
  'nbest_risk': {'dim': None, 'dtype': 'float32', 'feature_dim_axis': None, 'shape': [], 'time_dim_axis': None},
  'nbest_score': {'dim': None, 'dtype': 'float32', 'feature_dim_axis': None, 'shape': [], 'time_dim_axis': None}}
optimizer_epsilon = 1e-08
preload_from_files = { 'base': { 'filename': '/u/zhou/asr-exps/librispeech/2021-01-22_phoneme-transducer/alias/02_no-stress_fullsum/train_ns-mono-eow_ss4_gt50_vgg-conformer_finetune_base-noGradNoise_OCLR8e-5/output/models/epoch.300',
            'ignore_missing': True,
            'init_for_train': True}}
save_interval = 1
start_batch = 'auto'
start_epoch = 'auto'
target = 'classes'
task = 'train'
train = { 'class': 'ExternSprintDataset',
  'nbest': 4,
  'partitionEpoch': 20,
  'reduce_target_factor': 4,
  'sprintConfigStr': '--config=sprint.train.config --*.LOGFILE=nn-trainer.train.log --*.TASK=1 --*.corpus.segment-order-shuffle=true '
                     '--*.segment-order-sort-by-time-length=true --*.segment-order-sort-by-time-length-chunk-size=400000',
  'sprintTrainerExecPath': '/u/zhou/rasr-dev/arch/linux-x86_64-standard-label_sync_decoding/nn-trainer.linux-x86_64-standard-label_sync_decoding'}
train_dependency_file = '/u/zhou/asr-exps/librispeech/2021-01-22_phoneme-transducer/alias/03_no-stress_MBR_base-only-v2/recog_train-960_fullsum_base_epoch300_MBR-lattice-decoding_lm0.7/output/lattice.bundle'
truncation = -1
update_on_device = True
use_tensorflow = True
window = 1
config = {}

locals().update(**config)

# RNNT fullsum loss
def rnnt_loss(source, blank_label=0, input_type='logit', **kwargs):
  from extern.BergerMonotonicRNNTLoss import rnnt_loss
  probs = source(0, as_data=True, auto_convert=False)
  targets = source(1, as_data=True, auto_convert=False)
  encoder = source(2, as_data=True, auto_convert=False)
  enc_lens = encoder.get_sequence_lengths()
  dec_lens = targets.get_sequence_lengths()
  costs = rnnt_loss(probs.placeholder, targets.get_placeholder_as_batch_major(), enc_lens, dec_lens, blank_label=blank_label, input_type=input_type)
  costs.set_shape((None,))
  return costs

from TFNetworkLayer import _ConcatInputLayer, register_layer_class

class CompressedConcatLayer(_ConcatInputLayer):
  layer_class = "compressed_concat"

  def __init__(self, sources, **kwargs):
    super(CompressedConcatLayer, self).__init__(**kwargs)
    enc = sources[0].output
    dec = sources[1].output
    enc_placeholder = enc.get_placeholder_as_batch_major()
    dec_placeholder = dec.get_placeholder_as_batch_major()
    enc_lens = enc.get_sequence_lengths()
    dec_lens = dec.get_sequence_lengths()

    import tensorflow as tf
    B = tf.shape(enc_placeholder)[0]
    F1 = enc_placeholder.shape[-1]
    F2 = dec_placeholder.shape[-1]
    b = tf.constant(0)
    out = tf.TensorArray(dtype=tf.float32, size=B, dynamic_size=False, element_shape=[None, F1+F2], infer_shape=False, clear_after_read=True)
    cond = lambda b, _: tf.less(b, B)
    def body(b, out):
      encT = tf.pad(enc_placeholder[b, :enc_lens[b]], [(0, 0), (0, F2)], mode='CONSTANT', constant_values=0) # (T, F)
      decU = tf.pad(dec_placeholder[b, :dec_lens[b]], [(0, 0), (F1, 0)], mode='CONSTANT', constant_values=0) # (U+1, F)
      return b+1, out.write(b, tf.reshape(tf.expand_dims(encT, 1) + tf.expand_dims(decU, 0), [enc_lens[b] * dec_lens[b], F1+F2])) # (T * U+1, F)
    b, out = tf.while_loop(cond, body, [b, out])

    self.output.placeholder = out.concat() # (sum_B T_b * U_b+1, F)
    self.output.size_placeholder = {0: tf.tensordot(enc_lens, dec_lens, axes=1)}

  @classmethod
  def get_out_data_from_opts(cls, name, sources, **kwargs):
    from TFUtil import Data
    assert len(sources) == 2
    F = sources[0].output.dim + sources[1].output.dim
    return Data(
      name="%s_output" % name,
      shape=(None, F),
      dtype="float32",
      batch_dim_axis=None,
      time_dim_axis=0,
      feature_dim_axis=1)

register_layer_class(CompressedConcatLayer)

# iterative computation over NBest to solve memory issue (still N limit due to gradients)
# also similar batch settings as in fullsum training can be used
class IterativeNBestMBRLossLayer(_ConcatInputLayer):
  layer_class = 'iterative_nbest_mbr'

  def __init__(self, sources, nbest, use_nbest_score=False, renorm_scale=1.0,
               rnnt_loss_scale=0, blank_label=0, input_type='logit',
               reuse_joint=('_joint', 1024, 'tanh'), reuse_output=('_output', 79), **kwargs):
    super(IterativeNBestMBRLossLayer, self).__init__(**kwargs)
    enc_out = sources[0].output # encoder output of B utterances
    dec_out = sources[1].output # predNN output of B*N NBest seqs
    seq_out = sources[2].output # NBest seqs
    enc = enc_out.get_placeholder_as_batch_major()
    dec = dec_out.get_placeholder_as_batch_major()
    seq = seq_out.get_placeholder_as_batch_major()
    enc_lens = enc_out.get_sequence_lengths()
    dec_lens = dec_out.get_sequence_lengths()
    seq_lens = seq_out.get_sequence_lengths()
    # additional scores used in NBest generation, e.g. lm_score
    add_scores = sources[3].output.get_placeholder_as_batch_major() # (B*N,)
    nbest_risks = sources[4].output.get_placeholder_as_batch_major()
    # all further input regarded as computation dependency for memory issue
    if len(sources) >= 6:
      extra_dep = [s.output.placeholder for s in sources[5:]]
    else: extra_dep = []

    import tensorflow as tf
    import numpy as np
    from TFUtil import dot, reuse_name_scope, dropout, get_activation_function
    from extern.BergerMonotonicRNNTLoss import rnnt_loss

    B = tf.shape(enc)[0]
    BN = tf.shape(add_scores)[0]
    F1 = enc.shape[-1]
    F2 = dec.shape[-1]
   
    # reuse joint and output layers params for computation 
    # same param_name under different reuse_layer scope: use param_name+suffix for map
    # fixed format (e.g. default args): param_name_suffix, dim, activation
    assert len(reuse_joint) >= 3 and len(reuse_output) >= 2
    with self.var_creation_scope(param_name_suffix=reuse_joint[0]):
      W_joint = self.add_param(
          tf.get_variable(name="W", shape=(F1+F2, reuse_joint[1]), dtype=tf.float32), 
          param_name_suffix=reuse_joint[0]) 
      b_joint = self.add_param(
          tf.get_variable(name="b", shape=(reuse_joint[1],), dtype=tf.float32), 
          param_name_suffix=reuse_joint[0])
    joint_act_func = get_activation_function(reuse_joint[2])
    with self.var_creation_scope(param_name_suffix=reuse_output[0]):
      W_output = self.add_param(
          tf.get_variable(name="W", shape=(reuse_joint[1], reuse_output[1]), dtype=tf.float32), 
          param_name_suffix=reuse_output[0])
      b_output = self.add_param(
          tf.get_variable(name="b", shape=(reuse_output[1],) , dtype=tf.float32), 
          param_name_suffix=reuse_output[0])
    # no L2 on output layer
    self.no_l2_params = ['W'+reuse_output[0], 'b'+reuse_output[0]]
    
    # inner loop over each seq for no-zero-padding concatenaton
    # possible dynamic-NBest: empty seqs will have negligible computation cost 
    def iterative_compress_concat(dec_B, dec_lens_B):
      b = tf.constant(0, dtype=tf.int32)
      cond = lambda b, _: tf.less(b, B)
      out = tf.TensorArray(dtype=tf.float32, size=B, dynamic_size=False, element_shape=[None, F1+F2], infer_shape=False, clear_after_read=True)
      def body(b, out):
        encT = tf.pad(enc[b, :enc_lens[b]], [(0, 0), (0, F2)], mode='CONSTANT', constant_values=0) # (T, F)
        decU = tf.pad(dec_B[b, :dec_lens_B[b]], [(0, 0), (F1, 0)], mode='CONSTANT', constant_values=0) # (U+1, F)
        return b+1, out.write(b, tf.reshape(tf.expand_dims(encT, 1) + tf.expand_dims(decU, 0), [enc_lens[b] * dec_lens_B[b], F1+F2])) # (T * U+1, F)
      b, out = tf.while_loop(cond, body, [b, out])
      return out.concat() # (sum_B T_b * U_b+1, F)

    # iterative computation: B seqs/iteration with gap N (deactivate parallelization by dependency)
    score_list = []
    for n in range(nbest):
      with tf.control_dependencies(score_list + extra_dep):
        indices = tf.range(n, BN, delta=nbest)
        dec_B = tf.gather(dec, indices, axis=0)
        dec_lens_B = tf.gather(dec_lens, indices, axis=0)
        compress_concat = iterative_compress_concat(dec_B, dec_lens_B)
        # forward jointNN
        compress_concat = self.network.cond_on_train(
            lambda: dropout(compress_concat, keep_prob=1 - self.dropout, noise_shape=(1, F1+F2),
                            seed=self.network.random.randint(2 ** 31)),
            lambda: compress_concat)
        joint = tf.add(dot(compress_concat, W_joint), b_joint, name="add_bias")
        if joint_act_func:
          joint = joint_act_func(joint)
        output = tf.add(dot(joint, W_output), b_output, name="add_bias")
        # compute rnnt fullsum loss
        seq_B = tf.gather(seq, indices, axis=0)
        seq_lens_B = tf.gather(seq_lens, indices, axis=0)
        scores = rnnt_loss(output, seq_B, enc_lens, seq_lens_B, blank_label=blank_label, input_type=input_type)
        scores.set_shape((None,)) # (B,)
        score_list.append(tf.scatter_nd(tf.expand_dims(indices, -1), scores, [BN]))

    # -log(P_rnnt) for all NBest seqs (B*N,)
    nbest_scores = tf.add_n(score_list) # ensure dependency
    # ground-truth seqs mask
    ref_mask = tf.where(tf.equal(nbest_risks, 0), tf.ones_like(nbest_risks), tf.zeros_like(nbest_risks))
    ref_mask = tf.where(tf.greater(seq_lens, 0), ref_mask, tf.zeros_like(ref_mask))
    # optional scaled rnnt-loss
    if rnnt_loss_scale > 0:
      rnnt_loss = rnnt_loss_scale * tf.reduce_sum(nbest_scores * ref_mask)
    else: rnnt_loss = 0
    # add additional score and gobal scale before renormalization
    if use_nbest_score:
      nbest_scores = nbest_scores + add_scores
    nbest_scores = nbest_scores * renorm_scale 
    # possible dynamic-NBest: filter out empty seqs
    empty_scores = tf.ones_like(nbest_scores) * np.inf
    nbest_scores = tf.where(tf.equal(seq_lens, 0), empty_scores, nbest_scores)
    # renormalization within each (dynamic) NBest
    norm_nbest = tf.reshape(nbest_scores, [-1, nbest]) # (B, N)
    norm_nbest = tf.nn.softmax(-norm_nbest, axis=-1)
    # multiply risk of each hyp (explicit zero-out empty seqs to be sure)
    nbest_mbr = tf.reshape(norm_nbest, [-1]) * nbest_risks
    nbest_mbr = tf.where(tf.equal(seq_lens, 0), tf.zeros_like(nbest_mbr), nbest_mbr)
    # directly a scalar MBR loss + optional scaled rnnt-loss
    self.output.placeholder = tf.reduce_sum(nbest_mbr) + rnnt_loss

  @classmethod
  def get_out_data_from_opts(cls, name, sources, **kwargs):
    from TFUtil import Data
    return Data(
      name="%s_output" % name,
      shape=(),
      dtype="float32",
      batch_dim_axis=None,
      time_dim_axis=None,
      feature_dim_axis=None)

  def get_params_l2_norm(self):
    import tensorflow as tf
    return 2 * sum([tf.nn.l2_loss(param) for (name, param) in sorted(self.params.items()) if not name in self.no_l2_params])

register_layer_class(IterativeNBestMBRLossLayer)


